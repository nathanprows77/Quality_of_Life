{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data read-in/prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn \n",
    "\n",
    "# !pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update tensorflow\n",
    "\n",
    "# !pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Linear Regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>year</th>\n",
       "      <th>Name</th>\n",
       "      <th>Population</th>\n",
       "      <th>HHI</th>\n",
       "      <th>PovertyRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>700703</td>\n",
       "      <td>69014</td>\n",
       "      <td>9.292239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>6337373</td>\n",
       "      <td>50752</td>\n",
       "      <td>15.835820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2895928</td>\n",
       "      <td>40149</td>\n",
       "      <td>17.846507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2011</td>\n",
       "      <td>California</td>\n",
       "      <td>36969200</td>\n",
       "      <td>61632</td>\n",
       "      <td>14.096818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State  year        Name  Population    HHI  PovertyRate\n",
       "0      1  2011     Alabama     4747424  42934    17.133186\n",
       "1      2  2011      Alaska      700703  69014     9.292239\n",
       "2      4  2011     Arizona     6337373  50752    15.835820\n",
       "3      5  2011    Arkansas     2895928  40149    17.846507\n",
       "4      6  2011  California    36969200  61632    14.096818"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the census csv into a pandas DataFrame\n",
    "\n",
    "census = pd.read_csv('../Resources/Tableau_clean/census_all.csv')\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>year</th>\n",
       "      <th>state_name</th>\n",
       "      <th>Population</th>\n",
       "      <th>HHI</th>\n",
       "      <th>PovertyRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>700703</td>\n",
       "      <td>69014</td>\n",
       "      <td>9.292239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>6337373</td>\n",
       "      <td>50752</td>\n",
       "      <td>15.835820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2895928</td>\n",
       "      <td>40149</td>\n",
       "      <td>17.846507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2011</td>\n",
       "      <td>California</td>\n",
       "      <td>36969200</td>\n",
       "      <td>61632</td>\n",
       "      <td>14.096818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>51</td>\n",
       "      <td>2015</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>8256630</td>\n",
       "      <td>65015</td>\n",
       "      <td>11.164628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>53</td>\n",
       "      <td>2015</td>\n",
       "      <td>Washington</td>\n",
       "      <td>6985464</td>\n",
       "      <td>61062</td>\n",
       "      <td>13.005750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>54</td>\n",
       "      <td>2015</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>1851420</td>\n",
       "      <td>41751</td>\n",
       "      <td>17.466809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>55</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>5742117</td>\n",
       "      <td>53357</td>\n",
       "      <td>12.614651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  year     state_name  Population    HHI  PovertyRate\n",
       "0        1  2011        Alabama     4747424  42934    17.133186\n",
       "1        2  2011         Alaska      700703  69014     9.292239\n",
       "2        4  2011        Arizona     6337373  50752    15.835820\n",
       "3        5  2011       Arkansas     2895928  40149    17.846507\n",
       "4        6  2011     California    36969200  61632    14.096818\n",
       "..     ...   ...            ...         ...    ...          ...\n",
       "250     51  2015       Virginia     8256630  65015    11.164628\n",
       "251     53  2015     Washington     6985464  61062    13.005750\n",
       "252     54  2015  West Virginia     1851420  41751    17.466809\n",
       "253     55  2015      Wisconsin     5742117  53357    12.614651\n",
       "254     56  2015        Wyoming      579679  58840    11.212240\n",
       "\n",
       "[255 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename State column for joining\n",
    "\n",
    "census = census.rename(columns={'Name': 'state_name'})\n",
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>year</th>\n",
       "      <th>state_name</th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "      <th>one_ambulatory_visit</th>\n",
       "      <th>diabetic_enrollees_age_65_to_75</th>\n",
       "      <th>average_diabetic_enrollees_hemoglobin_a1c_test</th>\n",
       "      <th>average_diabetic_enrollees_eye_exam</th>\n",
       "      <th>average_diabetic_enrollees_blood_lipids_test</th>\n",
       "      <th>average_female_enrollees_age_67_to_69</th>\n",
       "      <th>average_female_age_67_to_69_mammogram</th>\n",
       "      <th>beneficiaries_part_a_eligible</th>\n",
       "      <th>leg_amputations_per_1000_enrollees</th>\n",
       "      <th>discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>63.3</td>\n",
       "      <td>80.3</td>\n",
       "      <td>42267.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>501422.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>49648.0</td>\n",
       "      <td>70.9</td>\n",
       "      <td>5449.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>55.8</td>\n",
       "      <td>66.9</td>\n",
       "      <td>5151.0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>54928.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>53.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>465298.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>50991.0</td>\n",
       "      <td>78.5</td>\n",
       "      <td>66.1</td>\n",
       "      <td>75.8</td>\n",
       "      <td>43614.0</td>\n",
       "      <td>64.3</td>\n",
       "      <td>501103.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>327939.0</td>\n",
       "      <td>80.7</td>\n",
       "      <td>40202.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>66.1</td>\n",
       "      <td>76.2</td>\n",
       "      <td>29290.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>345431.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>California</td>\n",
       "      <td>2238140.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>243999.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>64.1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>190971.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2378472.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>49.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>49.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>832699.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>98165.0</td>\n",
       "      <td>87.6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>83135.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>703266.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>42.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Washington</td>\n",
       "      <td>610922.0</td>\n",
       "      <td>78.5</td>\n",
       "      <td>56474.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>67.7</td>\n",
       "      <td>76.3</td>\n",
       "      <td>56238.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>510796.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>206961.0</td>\n",
       "      <td>80.8</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>84.7</td>\n",
       "      <td>59.9</td>\n",
       "      <td>78.2</td>\n",
       "      <td>20777.0</td>\n",
       "      <td>59.1</td>\n",
       "      <td>171837.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>52.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>474364.0</td>\n",
       "      <td>79.8</td>\n",
       "      <td>46596.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>69.7</td>\n",
       "      <td>81.6</td>\n",
       "      <td>44595.0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>418646.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.5</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58899.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state_id  year     state_name  beneficiaries_part_b  \\\n",
       "0         1.0  2011        Alabama              478784.0   \n",
       "1         2.0  2011         Alaska               49648.0   \n",
       "2         3.0  2011        Arizona              465298.0   \n",
       "3         4.0  2011       Arkansas              327939.0   \n",
       "4         5.0  2011     California             2238140.0   \n",
       "..        ...   ...            ...                   ...   \n",
       "250      49.0  2015       Virginia              832699.0   \n",
       "251      50.0  2015     Washington              610922.0   \n",
       "252      51.0  2015  West Virginia              206961.0   \n",
       "253      52.0  2015      Wisconsin              474364.0   \n",
       "254      53.0  2015        Wyoming               72959.0   \n",
       "\n",
       "     one_ambulatory_visit  diabetic_enrollees_age_65_to_75  \\\n",
       "0                    82.5                          69691.0   \n",
       "1                    70.9                           5449.0   \n",
       "2                    78.2                          50991.0   \n",
       "3                    80.7                          40202.0   \n",
       "4                    72.7                         243999.0   \n",
       "..                    ...                              ...   \n",
       "250                  83.3                          98165.0   \n",
       "251                  78.5                          56474.0   \n",
       "252                  80.8                          29239.0   \n",
       "253                  79.8                          46596.0   \n",
       "254                  72.7                           6146.0   \n",
       "\n",
       "     average_diabetic_enrollees_hemoglobin_a1c_test  \\\n",
       "0                                              83.9   \n",
       "1                                              74.5   \n",
       "2                                              78.5   \n",
       "3                                              82.5   \n",
       "4                                              80.6   \n",
       "..                                              ...   \n",
       "250                                            87.6   \n",
       "251                                            86.6   \n",
       "252                                            84.7   \n",
       "253                                            91.0   \n",
       "254                                            78.2   \n",
       "\n",
       "     average_diabetic_enrollees_eye_exam  \\\n",
       "0                                   63.3   \n",
       "1                                   55.8   \n",
       "2                                   66.1   \n",
       "3                                   66.1   \n",
       "4                                   64.1   \n",
       "..                                   ...   \n",
       "250                                 70.0   \n",
       "251                                 67.7   \n",
       "252                                 59.9   \n",
       "253                                 69.7   \n",
       "254                                 62.8   \n",
       "\n",
       "     average_diabetic_enrollees_blood_lipids_test  \\\n",
       "0                                            80.3   \n",
       "1                                            66.9   \n",
       "2                                            75.8   \n",
       "3                                            76.2   \n",
       "4                                            78.0   \n",
       "..                                            ...   \n",
       "250                                          82.0   \n",
       "251                                          76.3   \n",
       "252                                          78.2   \n",
       "253                                          81.6   \n",
       "254                                          59.5   \n",
       "\n",
       "     average_female_enrollees_age_67_to_69  \\\n",
       "0                                  42267.0   \n",
       "1                                   5151.0   \n",
       "2                                  43614.0   \n",
       "3                                  29290.0   \n",
       "4                                 190971.0   \n",
       "..                                     ...   \n",
       "250                                83135.0   \n",
       "251                                56238.0   \n",
       "252                                20777.0   \n",
       "253                                44595.0   \n",
       "254                                 7201.0   \n",
       "\n",
       "     average_female_age_67_to_69_mammogram  beneficiaries_part_a_eligible  \\\n",
       "0                                     62.8                       501422.0   \n",
       "1                                     55.3                        54928.0   \n",
       "2                                     64.3                       501103.0   \n",
       "3                                     58.3                       345431.0   \n",
       "4                                     59.0                      2378472.0   \n",
       "..                                     ...                            ...   \n",
       "250                                   64.5                       703266.0   \n",
       "251                                   60.0                       510796.0   \n",
       "252                                   59.1                       171837.0   \n",
       "253                                   71.9                       418646.0   \n",
       "254                                   56.0                        58899.0   \n",
       "\n",
       "     leg_amputations_per_1000_enrollees  \\\n",
       "0                                  0.99   \n",
       "1                                  0.81   \n",
       "2                                  0.57   \n",
       "3                                  0.85   \n",
       "4                                  0.63   \n",
       "..                                  ...   \n",
       "250                                0.53   \n",
       "251                                0.46   \n",
       "252                                0.90   \n",
       "253                                0.65   \n",
       "254                                0.39   \n",
       "\n",
       "     discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees  \n",
       "0                                                 76.4                   \n",
       "1                                                 53.1                   \n",
       "2                                                 51.4                   \n",
       "3                                                 77.0                   \n",
       "4                                                 49.9                   \n",
       "..                                                 ...                   \n",
       "250                                               42.8                   \n",
       "251                                               32.7                   \n",
       "252                                               75.0                   \n",
       "253                                               45.0                   \n",
       "254                                               43.1                   \n",
       "\n",
       "[255 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the medicare csv into a pandas DataFrame\n",
    "\n",
    "medicare = pd.read_csv('../Resources/Tableau_clean/medicare_all.csv')\n",
    "medicare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_id',\n",
       " 'year',\n",
       " 'state_name',\n",
       " 'beneficiaries_part_b',\n",
       " 'one_ambulatory_visit',\n",
       " 'diabetic_enrollees_age_65_to_75',\n",
       " 'average_diabetic_enrollees_hemoglobin_a1c_test',\n",
       " 'average_diabetic_enrollees_eye_exam',\n",
       " 'average_diabetic_enrollees_blood_lipids_test',\n",
       " 'average_female_enrollees_age_67_to_69',\n",
       " 'average_female_age_67_to_69_mammogram',\n",
       " 'beneficiaries_part_a_eligible',\n",
       " 'leg_amputations_per_1000_enrollees',\n",
       " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify column names for joining\n",
    "\n",
    "list(medicare.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>year</th>\n",
       "      <th>state_name</th>\n",
       "      <th>Population</th>\n",
       "      <th>HHI</th>\n",
       "      <th>PovertyRate</th>\n",
       "      <th>state_id</th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "      <th>one_ambulatory_visit</th>\n",
       "      <th>diabetic_enrollees_age_65_to_75</th>\n",
       "      <th>average_diabetic_enrollees_hemoglobin_a1c_test</th>\n",
       "      <th>average_diabetic_enrollees_eye_exam</th>\n",
       "      <th>average_diabetic_enrollees_blood_lipids_test</th>\n",
       "      <th>average_female_enrollees_age_67_to_69</th>\n",
       "      <th>average_female_age_67_to_69_mammogram</th>\n",
       "      <th>beneficiaries_part_a_eligible</th>\n",
       "      <th>leg_amputations_per_1000_enrollees</th>\n",
       "      <th>discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>63.3</td>\n",
       "      <td>80.3</td>\n",
       "      <td>42267.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>501422.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>492195.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>72392.0</td>\n",
       "      <td>84.2</td>\n",
       "      <td>63.2</td>\n",
       "      <td>80.7</td>\n",
       "      <td>42535.0</td>\n",
       "      <td>62.7</td>\n",
       "      <td>517526.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>71.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>498123.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>74492.0</td>\n",
       "      <td>84.9</td>\n",
       "      <td>63.8</td>\n",
       "      <td>81.8</td>\n",
       "      <td>44502.0</td>\n",
       "      <td>62.7</td>\n",
       "      <td>525015.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>506023.0</td>\n",
       "      <td>83.2</td>\n",
       "      <td>76238.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>63.7</td>\n",
       "      <td>81.1</td>\n",
       "      <td>48751.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>534296.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>510586.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>68202.0</td>\n",
       "      <td>86.1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>52169.0</td>\n",
       "      <td>63.1</td>\n",
       "      <td>404987.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>61634.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>64.7</td>\n",
       "      <td>58.7</td>\n",
       "      <td>5517.0</td>\n",
       "      <td>57.4</td>\n",
       "      <td>65932.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>55.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>64431.0</td>\n",
       "      <td>73.3</td>\n",
       "      <td>6017.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>63.8</td>\n",
       "      <td>59.4</td>\n",
       "      <td>5519.0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>69056.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>52.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>68066.0</td>\n",
       "      <td>74.6</td>\n",
       "      <td>6475.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>62.7</td>\n",
       "      <td>60.2</td>\n",
       "      <td>5844.0</td>\n",
       "      <td>57.1</td>\n",
       "      <td>73043.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>47.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>70457.0</td>\n",
       "      <td>73.8</td>\n",
       "      <td>6832.0</td>\n",
       "      <td>76.7</td>\n",
       "      <td>63.2</td>\n",
       "      <td>59.7</td>\n",
       "      <td>6498.0</td>\n",
       "      <td>56.3</td>\n",
       "      <td>75824.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>46.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.5</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58899.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1275 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State  year state_name  Population    HHI  PovertyRate  state_id  \\\n",
       "0         1  2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "1         1  2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "2         1  2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "3         1  2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "4         1  2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "...     ...   ...        ...         ...    ...          ...       ...   \n",
       "1270     56  2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "1271     56  2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "1272     56  2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "1273     56  2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "1274     56  2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "\n",
       "      beneficiaries_part_b  one_ambulatory_visit  \\\n",
       "0                 478784.0                  82.5   \n",
       "1                 492195.0                  82.8   \n",
       "2                 498123.0                  83.3   \n",
       "3                 506023.0                  83.2   \n",
       "4                 510586.0                  83.3   \n",
       "...                    ...                   ...   \n",
       "1270               61634.0                  73.0   \n",
       "1271               64431.0                  73.3   \n",
       "1272               68066.0                  74.6   \n",
       "1273               70457.0                  73.8   \n",
       "1274               72959.0                  72.7   \n",
       "\n",
       "      diabetic_enrollees_age_65_to_75  \\\n",
       "0                             69691.0   \n",
       "1                             72392.0   \n",
       "2                             74492.0   \n",
       "3                             76238.0   \n",
       "4                             68202.0   \n",
       "...                               ...   \n",
       "1270                           5750.0   \n",
       "1271                           6017.0   \n",
       "1272                           6475.0   \n",
       "1273                           6832.0   \n",
       "1274                           6146.0   \n",
       "\n",
       "      average_diabetic_enrollees_hemoglobin_a1c_test  \\\n",
       "0                                               83.9   \n",
       "1                                               84.2   \n",
       "2                                               84.9   \n",
       "3                                               85.0   \n",
       "4                                               86.1   \n",
       "...                                              ...   \n",
       "1270                                            74.7   \n",
       "1271                                            74.7   \n",
       "1272                                            75.4   \n",
       "1273                                            76.7   \n",
       "1274                                            78.2   \n",
       "\n",
       "      average_diabetic_enrollees_eye_exam  \\\n",
       "0                                    63.3   \n",
       "1                                    63.2   \n",
       "2                                    63.8   \n",
       "3                                    63.7   \n",
       "4                                    64.0   \n",
       "...                                   ...   \n",
       "1270                                 64.7   \n",
       "1271                                 63.8   \n",
       "1272                                 62.7   \n",
       "1273                                 63.2   \n",
       "1274                                 62.8   \n",
       "\n",
       "      average_diabetic_enrollees_blood_lipids_test  \\\n",
       "0                                             80.3   \n",
       "1                                             80.7   \n",
       "2                                             81.8   \n",
       "3                                             81.1   \n",
       "4                                             81.0   \n",
       "...                                            ...   \n",
       "1270                                          58.7   \n",
       "1271                                          59.4   \n",
       "1272                                          60.2   \n",
       "1273                                          59.7   \n",
       "1274                                          59.5   \n",
       "\n",
       "      average_female_enrollees_age_67_to_69  \\\n",
       "0                                   42267.0   \n",
       "1                                   42535.0   \n",
       "2                                   44502.0   \n",
       "3                                   48751.0   \n",
       "4                                   52169.0   \n",
       "...                                     ...   \n",
       "1270                                 5517.0   \n",
       "1271                                 5519.0   \n",
       "1272                                 5844.0   \n",
       "1273                                 6498.0   \n",
       "1274                                 7201.0   \n",
       "\n",
       "      average_female_age_67_to_69_mammogram  beneficiaries_part_a_eligible  \\\n",
       "0                                      62.8                       501422.0   \n",
       "1                                      62.7                       517526.0   \n",
       "2                                      62.7                       525015.0   \n",
       "3                                      62.8                       534296.0   \n",
       "4                                      63.1                       404987.0   \n",
       "...                                     ...                            ...   \n",
       "1270                                   57.4                        65932.0   \n",
       "1271                                   57.9                        69056.0   \n",
       "1272                                   57.1                        73043.0   \n",
       "1273                                   56.3                        75824.0   \n",
       "1274                                   56.0                        58899.0   \n",
       "\n",
       "      leg_amputations_per_1000_enrollees  \\\n",
       "0                                   0.99   \n",
       "1                                   0.90   \n",
       "2                                   0.87   \n",
       "3                                   0.83   \n",
       "4                                   0.79   \n",
       "...                                  ...   \n",
       "1270                                0.62   \n",
       "1271                                0.46   \n",
       "1272                                0.67   \n",
       "1273                                0.38   \n",
       "1274                                0.39   \n",
       "\n",
       "      discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees  \n",
       "0                                                  76.4                   \n",
       "1                                                  71.5                   \n",
       "2                                                  65.4                   \n",
       "3                                                  61.1                   \n",
       "4                                                  62.0                   \n",
       "...                                                 ...                   \n",
       "1270                                               55.2                   \n",
       "1271                                               52.7                   \n",
       "1272                                               47.9                   \n",
       "1273                                               46.1                   \n",
       "1274                                               43.1                   \n",
       "\n",
       "[1275 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join csvs\n",
    "\n",
    "data = pd.merge(census,\n",
    "                 medicare[['state_id', 'state_name', 'beneficiaries_part_b', 'one_ambulatory_visit', 'diabetic_enrollees_age_65_to_75',\n",
    " 'average_diabetic_enrollees_hemoglobin_a1c_test', 'average_diabetic_enrollees_eye_exam', 'average_diabetic_enrollees_blood_lipids_test',\n",
    " 'average_female_enrollees_age_67_to_69', 'average_female_age_67_to_69_mammogram', 'beneficiaries_part_a_eligible', 'leg_amputations_per_1000_enrollees',\n",
    " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees']],\n",
    "                 on='state_name')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>Days_with_AQI</th>\n",
       "      <th>Year</th>\n",
       "      <th>Good_Days</th>\n",
       "      <th>Moderate_Days</th>\n",
       "      <th>Unhealthy_Days</th>\n",
       "      <th>Very_Unhealthy_Days</th>\n",
       "      <th>Hazardous_Days</th>\n",
       "      <th>Days_CO</th>\n",
       "      <th>Days_NO2</th>\n",
       "      <th>Days_Ozone</th>\n",
       "      <th>Days_SO2</th>\n",
       "      <th>Days_PM2.5</th>\n",
       "      <th>Days_PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>248.53</td>\n",
       "      <td>2011</td>\n",
       "      <td>171.79</td>\n",
       "      <td>72.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>158.63</td>\n",
       "      <td>0.16</td>\n",
       "      <td>84.89</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>274.50</td>\n",
       "      <td>2011</td>\n",
       "      <td>235.25</td>\n",
       "      <td>34.88</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>176.25</td>\n",
       "      <td>20.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>320.62</td>\n",
       "      <td>2011</td>\n",
       "      <td>177.15</td>\n",
       "      <td>117.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.15</td>\n",
       "      <td>167.15</td>\n",
       "      <td>16.54</td>\n",
       "      <td>27.77</td>\n",
       "      <td>106.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>216.88</td>\n",
       "      <td>2011</td>\n",
       "      <td>154.47</td>\n",
       "      <td>59.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>108.76</td>\n",
       "      <td>14.76</td>\n",
       "      <td>90.35</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>345.65</td>\n",
       "      <td>2011</td>\n",
       "      <td>193.17</td>\n",
       "      <td>120.37</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6.91</td>\n",
       "      <td>197.43</td>\n",
       "      <td>0.09</td>\n",
       "      <td>129.24</td>\n",
       "      <td>11.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>261.00</td>\n",
       "      <td>2015</td>\n",
       "      <td>228.14</td>\n",
       "      <td>32.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>35.06</td>\n",
       "      <td>141.26</td>\n",
       "      <td>0.97</td>\n",
       "      <td>73.66</td>\n",
       "      <td>8.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Washington</td>\n",
       "      <td>345.83</td>\n",
       "      <td>2015</td>\n",
       "      <td>292.76</td>\n",
       "      <td>48.14</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.69</td>\n",
       "      <td>47.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.21</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>280.47</td>\n",
       "      <td>2015</td>\n",
       "      <td>234.07</td>\n",
       "      <td>45.20</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>145.53</td>\n",
       "      <td>40.47</td>\n",
       "      <td>81.20</td>\n",
       "      <td>13.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>291.79</td>\n",
       "      <td>2015</td>\n",
       "      <td>245.86</td>\n",
       "      <td>42.68</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>191.43</td>\n",
       "      <td>14.54</td>\n",
       "      <td>84.86</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>309.42</td>\n",
       "      <td>2015</td>\n",
       "      <td>262.58</td>\n",
       "      <td>45.68</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.58</td>\n",
       "      <td>235.89</td>\n",
       "      <td>0.53</td>\n",
       "      <td>29.32</td>\n",
       "      <td>42.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state_name  Days_with_AQI  Year  Good_Days  Moderate_Days  \\\n",
       "0          Alabama         248.53  2011     171.79          72.37   \n",
       "1           Alaska         274.50  2011     235.25          34.88   \n",
       "2          Arizona         320.62  2011     177.15         117.00   \n",
       "3         Arkansas         216.88  2011     154.47          59.18   \n",
       "4       California         345.65  2011     193.17         120.37   \n",
       "..             ...            ...   ...        ...            ...   \n",
       "250       Virginia         261.00  2015     228.14          32.34   \n",
       "251     Washington         345.83  2015     292.76          48.14   \n",
       "252  West Virginia         280.47  2015     234.07          45.20   \n",
       "253      Wisconsin         291.79  2015     245.86          42.68   \n",
       "254        Wyoming         309.42  2015     262.58          45.68   \n",
       "\n",
       "     Unhealthy_Days  Very_Unhealthy_Days  Hazardous_Days  Days_CO  Days_NO2  \\\n",
       "0              0.37                 0.00            0.37     0.11      0.00   \n",
       "1              0.62                 0.12            0.62     2.12      0.00   \n",
       "2              2.38                 1.00            2.38     0.00      3.15   \n",
       "3              0.12                 0.00            0.12     0.00      3.00   \n",
       "4              7.02                 0.37            7.02     0.17      6.91   \n",
       "..              ...                  ...             ...      ...       ...   \n",
       "250            0.00                 0.00            0.00     1.14     35.06   \n",
       "251            1.03                 0.07            1.03     0.00      2.69   \n",
       "252            0.07                 0.00            0.07     0.13      0.00   \n",
       "253            0.07                 0.00            0.07     0.00      0.71   \n",
       "254            0.21                 0.00            0.21     0.05      1.58   \n",
       "\n",
       "     Days_Ozone  Days_SO2  Days_PM2.5  Days_PM10  \n",
       "0        158.63      0.16       84.89       4.74  \n",
       "1         75.62      0.00      176.25      20.50  \n",
       "2        167.15     16.54       27.77     106.00  \n",
       "3        108.76     14.76       90.35       0.00  \n",
       "4        197.43      0.09      129.24      11.81  \n",
       "..          ...       ...         ...        ...  \n",
       "250      141.26      0.97       73.66       8.91  \n",
       "251       47.45      0.00      290.21       5.48  \n",
       "252      145.53     40.47       81.20      13.13  \n",
       "253      191.43     14.54       84.86       0.25  \n",
       "254      235.89      0.53       29.32      42.05  \n",
       "\n",
       "[255 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in Pollution data\n",
    "\n",
    "pollution = pd.read_csv('../Resources/Tableau_clean/pollution_all.csv')\n",
    "pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>year</th>\n",
       "      <th>state_name</th>\n",
       "      <th>Population</th>\n",
       "      <th>HHI</th>\n",
       "      <th>PovertyRate</th>\n",
       "      <th>state_id</th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "      <th>one_ambulatory_visit</th>\n",
       "      <th>diabetic_enrollees_age_65_to_75</th>\n",
       "      <th>...</th>\n",
       "      <th>Moderate_Days</th>\n",
       "      <th>Unhealthy_Days</th>\n",
       "      <th>Very_Unhealthy_Days</th>\n",
       "      <th>Hazardous_Days</th>\n",
       "      <th>Days_CO</th>\n",
       "      <th>Days_NO2</th>\n",
       "      <th>Days_Ozone</th>\n",
       "      <th>Days_SO2</th>\n",
       "      <th>Days_PM2.5</th>\n",
       "      <th>Days_PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>158.63</td>\n",
       "      <td>0.16</td>\n",
       "      <td>84.89</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>174.53</td>\n",
       "      <td>0.41</td>\n",
       "      <td>85.12</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>173.17</td>\n",
       "      <td>4.67</td>\n",
       "      <td>84.06</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>173.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>83.61</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>137.56</td>\n",
       "      <td>0.33</td>\n",
       "      <td>145.56</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.21</td>\n",
       "      <td>176.32</td>\n",
       "      <td>21.05</td>\n",
       "      <td>30.53</td>\n",
       "      <td>66.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.95</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.68</td>\n",
       "      <td>182.21</td>\n",
       "      <td>20.37</td>\n",
       "      <td>27.74</td>\n",
       "      <td>72.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.83</td>\n",
       "      <td>246.89</td>\n",
       "      <td>3.67</td>\n",
       "      <td>20.39</td>\n",
       "      <td>44.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.11</td>\n",
       "      <td>233.84</td>\n",
       "      <td>2.58</td>\n",
       "      <td>28.42</td>\n",
       "      <td>40.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.68</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.58</td>\n",
       "      <td>235.89</td>\n",
       "      <td>0.53</td>\n",
       "      <td>29.32</td>\n",
       "      <td>42.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6125 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State  year state_name  Population    HHI  PovertyRate  state_id  \\\n",
       "0         1  2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "1         1  2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "2         1  2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "3         1  2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "4         1  2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "...     ...   ...        ...         ...    ...          ...       ...   \n",
       "6120     56  2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "6121     56  2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "6122     56  2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "6123     56  2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "6124     56  2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "\n",
       "      beneficiaries_part_b  one_ambulatory_visit  \\\n",
       "0                 478784.0                  82.5   \n",
       "1                 478784.0                  82.5   \n",
       "2                 478784.0                  82.5   \n",
       "3                 478784.0                  82.5   \n",
       "4                 478784.0                  82.5   \n",
       "...                    ...                   ...   \n",
       "6120               72959.0                  72.7   \n",
       "6121               72959.0                  72.7   \n",
       "6122               72959.0                  72.7   \n",
       "6123               72959.0                  72.7   \n",
       "6124               72959.0                  72.7   \n",
       "\n",
       "      diabetic_enrollees_age_65_to_75  ...  Moderate_Days  Unhealthy_Days  \\\n",
       "0                             69691.0  ...          72.37            0.37   \n",
       "1                             69691.0  ...          58.82            0.24   \n",
       "2                             69691.0  ...          40.11            0.00   \n",
       "3                             69691.0  ...          46.11            0.00   \n",
       "4                             69691.0  ...          68.28            0.17   \n",
       "...                               ...  ...            ...             ...   \n",
       "6120                           6146.0  ...          60.16            0.26   \n",
       "6121                           6146.0  ...          80.95            0.63   \n",
       "6122                           6146.0  ...          60.00            0.06   \n",
       "6123                           6146.0  ...          43.32            0.32   \n",
       "6124                           6146.0  ...          45.68            0.21   \n",
       "\n",
       "      Very_Unhealthy_Days  Hazardous_Days  Days_CO  Days_NO2  Days_Ozone  \\\n",
       "0                    0.00            0.37     0.11      0.00      158.63   \n",
       "1                    0.00            0.24     0.00      0.00      174.53   \n",
       "2                    0.00            0.00     0.00      0.06      173.17   \n",
       "3                    0.00            0.00     0.00      0.39      173.06   \n",
       "4                    0.00            0.17     0.00      0.61      137.56   \n",
       "...                   ...             ...      ...       ...         ...   \n",
       "6120                 0.16            0.26     0.21      3.21      176.32   \n",
       "6121                 0.05            0.63     0.05      5.68      182.21   \n",
       "6122                 0.00            0.06     0.00      3.83      246.89   \n",
       "6123                 0.00            0.32     0.00      5.11      233.84   \n",
       "6124                 0.00            0.21     0.05      1.58      235.89   \n",
       "\n",
       "      Days_SO2  Days_PM2.5  Days_PM10  \n",
       "0         0.16       84.89       4.74  \n",
       "1         0.41       85.12       3.53  \n",
       "2         4.67       84.06       3.22  \n",
       "3         0.11       83.61       3.28  \n",
       "4         0.33      145.56       3.22  \n",
       "...        ...         ...        ...  \n",
       "6120     21.05       30.53      66.68  \n",
       "6121     20.37       27.74      72.37  \n",
       "6122      3.67       20.39      44.22  \n",
       "6123      2.58       28.42      40.37  \n",
       "6124      0.53       29.32      42.05  \n",
       "\n",
       "[6125 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join csvs\n",
    "\n",
    "data_all = pd.merge(data, pollution,on='state_name')\n",
    "data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 1: Comparing Household Income and Population to Medicare Part B Beneficiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State',\n",
       " 'year',\n",
       " 'state_name',\n",
       " 'Population',\n",
       " 'HHI',\n",
       " 'PovertyRate',\n",
       " 'state_id',\n",
       " 'beneficiaries_part_b',\n",
       " 'one_ambulatory_visit',\n",
       " 'diabetic_enrollees_age_65_to_75',\n",
       " 'average_diabetic_enrollees_hemoglobin_a1c_test',\n",
       " 'average_diabetic_enrollees_eye_exam',\n",
       " 'average_diabetic_enrollees_blood_lipids_test',\n",
       " 'average_female_enrollees_age_67_to_69',\n",
       " 'average_female_age_67_to_69_mammogram',\n",
       " 'beneficiaries_part_a_eligible',\n",
       " 'leg_amputations_per_1000_enrollees',\n",
       " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees',\n",
       " 'Days_with_AQI',\n",
       " 'Year',\n",
       " 'Good_Days',\n",
       " 'Moderate_Days',\n",
       " 'Unhealthy_Days',\n",
       " 'Very_Unhealthy_Days',\n",
       " 'Hazardous_Days',\n",
       " 'Days_CO',\n",
       " 'Days_NO2',\n",
       " 'Days_Ozone',\n",
       " 'Days_SO2',\n",
       " 'Days_PM2.5',\n",
       " 'Days_PM10']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify column names \n",
    "\n",
    "list(data_all.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['Population', 'PovertyRate']]\n",
    "y_data = data_all[['beneficiaries_part_b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split: \n",
    "<br>\n",
    "Use part of our data to train the algorithm, and part of it to evaluate how well the algorithm does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = y_data\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>PovertyRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>37325068</td>\n",
       "      <td>14.976798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>2967620</td>\n",
       "      <td>21.570551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4777326</td>\n",
       "      <td>17.631035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>998554</td>\n",
       "      <td>14.874308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>990785</td>\n",
       "      <td>14.445011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Population  PovertyRate\n",
       "539     37325068    14.976798\n",
       "2919     2967620    21.570551\n",
       "26       4777326    17.631035\n",
       "3190      998554    14.874308\n",
       "3152      990785    14.445011"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[211 101 101 ... 237  51  40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.1530590028303941\n",
      "Testing Data Score: 0.0926892950391645\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.07      0.33      0.11         6\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.08      0.17      0.11         6\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       0.00      0.00      0.00         7\n",
      "           9       0.00      0.00      0.00         6\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00         6\n",
      "          12       0.00      0.00      0.00         6\n",
      "          13       0.12      0.83      0.22         6\n",
      "          14       0.00      0.00      0.00         7\n",
      "          15       0.00      0.00      0.00         7\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.00      0.00      0.00         6\n",
      "          18       0.30      0.50      0.37         6\n",
      "          19       0.00      0.00      0.00         6\n",
      "          20       0.04      0.50      0.08         6\n",
      "          21       0.00      0.00      0.00         6\n",
      "          22       0.00      0.00      0.00         6\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.00      0.00      0.00         7\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       0.00      0.00      0.00         6\n",
      "          27       0.00      0.00      0.00         6\n",
      "          28       0.00      0.00      0.00         6\n",
      "          29       0.00      0.00      0.00         6\n",
      "          30       0.09      0.83      0.16         6\n",
      "          31       0.00      0.00      0.00         7\n",
      "          32       0.08      0.17      0.11         6\n",
      "          33       0.00      0.00      0.00         6\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00         7\n",
      "          37       0.00      0.00      0.00         6\n",
      "          38       0.11      0.17      0.13         6\n",
      "          39       0.00      0.00      0.00         6\n",
      "          40       0.00      0.00      0.00         6\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       0.00      0.00      0.00         6\n",
      "          43       0.06      0.50      0.11         6\n",
      "          44       0.14      0.33      0.20         6\n",
      "          45       0.00      0.00      0.00         6\n",
      "          46       0.00      0.00      0.00         7\n",
      "          47       0.00      0.00      0.00         6\n",
      "          48       0.00      0.00      0.00         6\n",
      "          49       0.20      0.33      0.25         6\n",
      "          50       0.00      0.00      0.00         7\n",
      "          51       0.00      0.00      0.00         6\n",
      "          52       0.17      0.67      0.27         6\n",
      "          53       0.07      0.33      0.12         6\n",
      "          54       0.00      0.00      0.00         6\n",
      "          55       0.25      0.17      0.20         6\n",
      "          56       0.00      0.00      0.00         6\n",
      "          57       0.00      0.00      0.00         6\n",
      "          58       0.00      0.00      0.00         6\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.00      0.00      0.00         6\n",
      "          61       0.00      0.00      0.00         6\n",
      "          62       0.00      0.00      0.00         7\n",
      "          63       0.00      0.00      0.00         6\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.00      0.00      0.00         6\n",
      "          66       0.00      0.00      0.00         6\n",
      "          67       0.00      0.00      0.00         6\n",
      "          68       0.00      0.00      0.00         6\n",
      "          69       0.11      0.33      0.17         6\n",
      "          70       0.00      0.00      0.00         7\n",
      "          71       0.00      0.00      0.00         6\n",
      "          72       0.00      0.00      0.00         7\n",
      "          73       0.00      0.00      0.00         7\n",
      "          74       0.00      0.00      0.00         7\n",
      "          75       0.00      0.00      0.00         6\n",
      "          76       0.21      0.67      0.32         6\n",
      "          77       0.00      0.00      0.00         6\n",
      "          78       0.00      0.00      0.00         7\n",
      "          79       0.00      0.00      0.00         6\n",
      "          80       0.08      0.17      0.11         6\n",
      "          81       0.14      0.17      0.15         6\n",
      "          82       0.11      0.17      0.13         6\n",
      "          83       0.08      0.50      0.14         6\n",
      "          84       0.00      0.00      0.00         6\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.14      0.17      0.15         6\n",
      "          87       0.00      0.00      0.00         6\n",
      "          88       0.13      0.50      0.21         6\n",
      "          89       0.00      0.00      0.00         6\n",
      "          90       0.00      0.00      0.00         6\n",
      "          91       0.00      0.00      0.00         6\n",
      "          92       0.00      0.00      0.00         6\n",
      "          93       0.00      0.00      0.00         6\n",
      "          94       0.14      0.33      0.20         6\n",
      "          95       0.25      0.17      0.20         6\n",
      "          96       0.18      0.50      0.26         6\n",
      "          97       0.00      0.00      0.00         7\n",
      "          98       0.00      0.00      0.00         7\n",
      "          99       0.00      0.00      0.00         7\n",
      "         100       0.00      0.00      0.00         6\n",
      "         101       0.00      0.00      0.00         6\n",
      "         102       0.00      0.00      0.00         7\n",
      "         103       0.00      0.00      0.00         6\n",
      "         104       0.00      0.00      0.00         6\n",
      "         105       0.11      0.33      0.17         6\n",
      "         106       0.14      0.67      0.24         6\n",
      "         107       0.09      0.50      0.15         6\n",
      "         108       0.00      0.00      0.00         6\n",
      "         109       0.00      0.00      0.00         7\n",
      "         110       0.11      0.17      0.13         6\n",
      "         111       0.00      0.00      0.00         6\n",
      "         112       0.00      0.00      0.00         7\n",
      "         113       0.00      0.00      0.00         7\n",
      "         114       0.20      0.33      0.25         6\n",
      "         115       0.17      0.67      0.28         6\n",
      "         116       0.00      0.00      0.00         7\n",
      "         117       0.00      0.00      0.00         7\n",
      "         118       0.00      0.00      0.00         6\n",
      "         119       0.00      0.00      0.00         6\n",
      "         120       0.06      0.33      0.11         6\n",
      "         121       0.00      0.00      0.00         6\n",
      "         122       0.12      0.33      0.17         6\n",
      "         123       0.00      0.00      0.00         6\n",
      "         124       0.00      0.00      0.00         6\n",
      "         125       0.00      0.00      0.00         6\n",
      "         126       0.00      0.00      0.00         7\n",
      "         127       0.18      0.67      0.29         6\n",
      "         128       0.00      0.00      0.00         6\n",
      "         129       0.11      0.50      0.18         6\n",
      "         130       0.00      0.00      0.00         6\n",
      "         131       0.00      0.00      0.00         7\n",
      "         132       0.00      0.00      0.00         6\n",
      "         133       0.00      0.00      0.00         6\n",
      "         134       0.05      0.17      0.08         6\n",
      "         135       0.00      0.00      0.00         6\n",
      "         136       0.00      0.00      0.00         6\n",
      "         137       0.00      0.00      0.00         6\n",
      "         138       0.05      0.33      0.09         6\n",
      "         139       0.00      0.00      0.00         7\n",
      "         140       0.00      0.00      0.00         7\n",
      "         141       0.00      0.00      0.00         7\n",
      "         142       0.08      0.17      0.11         6\n",
      "         143       0.00      0.00      0.00         6\n",
      "         144       0.00      0.00      0.00         7\n",
      "         145       0.00      0.00      0.00         6\n",
      "         146       0.00      0.00      0.00         6\n",
      "         147       0.05      0.33      0.08         6\n",
      "         148       0.00      0.00      0.00         6\n",
      "         149       0.00      0.00      0.00         6\n",
      "         150       0.00      0.00      0.00         6\n",
      "         151       0.00      0.00      0.00         6\n",
      "         152       0.00      0.00      0.00         6\n",
      "         153       0.00      0.00      0.00         6\n",
      "         154       0.00      0.00      0.00         6\n",
      "         155       0.00      0.00      0.00         6\n",
      "         156       0.00      0.00      0.00         6\n",
      "         157       0.00      0.00      0.00         7\n",
      "         158       0.00      0.00      0.00         6\n",
      "         159       0.00      0.00      0.00         7\n",
      "         160       0.00      0.00      0.00         6\n",
      "         161       0.00      0.00      0.00         6\n",
      "         162       0.18      0.50      0.26         6\n",
      "         163       0.00      0.00      0.00         6\n",
      "         164       0.00      0.00      0.00         7\n",
      "         165       0.29      0.33      0.31         6\n",
      "         166       0.00      0.00      0.00         6\n",
      "         167       0.00      0.00      0.00         7\n",
      "         168       0.00      0.00      0.00         6\n",
      "         169       0.07      0.50      0.12         6\n",
      "         170       0.00      0.00      0.00         6\n",
      "         171       0.00      0.00      0.00         6\n",
      "         172       0.00      0.00      0.00         6\n",
      "         173       0.00      0.00      0.00         7\n",
      "         174       0.00      0.00      0.00         6\n",
      "         175       0.00      0.00      0.00         7\n",
      "         176       0.00      0.00      0.00         6\n",
      "         177       0.00      0.00      0.00         6\n",
      "         178       0.09      0.33      0.14         6\n",
      "         179       0.16      0.50      0.24         6\n",
      "         180       0.15      0.33      0.21         6\n",
      "         181       0.09      0.17      0.12         6\n",
      "         182       0.00      0.00      0.00         6\n",
      "         183       0.00      0.00      0.00         7\n",
      "         184       0.17      0.33      0.22         6\n",
      "         185       0.00      0.00      0.00         6\n",
      "         186       0.00      0.00      0.00         6\n",
      "         187       0.00      0.00      0.00         6\n",
      "         188       0.00      0.00      0.00         6\n",
      "         189       0.00      0.00      0.00         6\n",
      "         190       0.00      0.00      0.00         7\n",
      "         191       0.00      0.00      0.00         7\n",
      "         192       0.10      0.50      0.16         6\n",
      "         193       0.07      0.17      0.10         6\n",
      "         194       0.00      0.00      0.00         6\n",
      "         195       0.00      0.00      0.00         6\n",
      "         196       0.00      0.00      0.00         6\n",
      "         197       0.00      0.00      0.00         7\n",
      "         198       0.13      0.50      0.21         6\n",
      "         199       0.00      0.00      0.00         7\n",
      "         200       0.00      0.00      0.00         7\n",
      "         201       0.25      0.17      0.20         6\n",
      "         202       0.00      0.00      0.00         6\n",
      "         203       0.00      0.00      0.00         6\n",
      "         204       0.15      0.67      0.24         6\n",
      "         205       0.00      0.00      0.00         7\n",
      "         206       0.00      0.00      0.00         6\n",
      "         207       0.00      0.00      0.00         7\n",
      "         208       0.00      0.00      0.00         6\n",
      "         209       0.18      0.33      0.24         6\n",
      "         210       0.00      0.00      0.00         6\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       0.00      0.00      0.00         6\n",
      "         213       0.14      0.17      0.15         6\n",
      "         214       0.00      0.00      0.00         7\n",
      "         215       0.00      0.00      0.00         6\n",
      "         216       0.09      0.17      0.12         6\n",
      "         217       0.00      0.00      0.00         7\n",
      "         218       0.00      0.00      0.00         6\n",
      "         219       0.00      0.00      0.00         6\n",
      "         220       0.00      0.00      0.00         6\n",
      "         221       0.12      0.33      0.17         6\n",
      "         222       0.00      0.00      0.00         7\n",
      "         223       0.07      0.17      0.10         6\n",
      "         224       0.00      0.00      0.00         7\n",
      "         225       0.00      0.00      0.00         7\n",
      "         226       0.00      0.00      0.00         6\n",
      "         227       0.00      0.00      0.00         6\n",
      "         228       0.00      0.00      0.00         6\n",
      "         229       0.15      0.33      0.21         6\n",
      "         230       0.00      0.00      0.00         6\n",
      "         231       0.11      0.33      0.17         6\n",
      "         232       0.08      0.17      0.11         6\n",
      "         233       0.00      0.00      0.00         6\n",
      "         234       0.00      0.00      0.00         7\n",
      "         235       0.17      0.33      0.22         6\n",
      "         236       0.00      0.00      0.00         7\n",
      "         237       0.00      0.00      0.00         6\n",
      "         238       0.00      0.00      0.00         7\n",
      "         239       0.20      0.67      0.31         6\n",
      "         240       0.10      0.33      0.15         6\n",
      "         241       0.00      0.00      0.00         7\n",
      "         242       0.00      0.00      0.00         7\n",
      "         243       0.17      0.33      0.22         6\n",
      "         244       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.09      1532\n",
      "   macro avg       0.03      0.10      0.05      1532\n",
      "weighted avg       0.03      0.09      0.05      1532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))\n",
    "\n",
    "# low precision scores indicate we need different data to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_all[\"beneficiaries_part_b\"]\n",
    "target_names = data_all[\"beneficiaries_part_b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all.drop(\"beneficiaries_part_b\", axis=1)\n",
    "data = data.drop(\"state_name\", axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.08647496702534946,\n",
       "  'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees'),\n",
       " (0.08477144810985966, 'average_female_enrollees_age_67_to_69'),\n",
       " (0.08094273530406029, 'average_diabetic_enrollees_hemoglobin_a1c_test'),\n",
       " (0.08091560709625481, 'one_ambulatory_visit'),\n",
       " (0.08088327090863957, 'average_diabetic_enrollees_blood_lipids_test'),\n",
       " (0.08076978303138017, 'leg_amputations_per_1000_enrollees'),\n",
       " (0.07992017812696549, 'average_female_age_67_to_69_mammogram'),\n",
       " (0.07912477023867939, 'beneficiaries_part_a_eligible'),\n",
       " (0.07860314610751411, 'diabetic_enrollees_age_65_to_75'),\n",
       " (0.07751666202508446, 'average_diabetic_enrollees_eye_exam'),\n",
       " (0.024206036915824486, 'state_id'),\n",
       " (0.022483655230185102, 'Population'),\n",
       " (0.02203430747434673, 'State'),\n",
       " (0.018955954997390768, 'HHI'),\n",
       " (0.01496701321958107, 'Days_PM10'),\n",
       " (0.014765998709163996, 'PovertyRate'),\n",
       " (0.013672101339385716, 'Days_PM2.5'),\n",
       " (0.012730763586957109, 'Days_Ozone'),\n",
       " (0.01012117273159476, 'Days_NO2'),\n",
       " (0.009819802906993861, 'Days_SO2'),\n",
       " (0.009678561183665786, 'Days_with_AQI'),\n",
       " (0.004751507566527845, 'Good_Days'),\n",
       " (0.0047142639797743534, 'Moderate_Days'),\n",
       " (0.0022771761190742254, 'Hazardous_Days'),\n",
       " (0.00216365055026379, 'Unhealthy_Days'),\n",
       " (0.0016328090785296036, 'Days_CO'),\n",
       " (0.0004335221453869027, 'Very_Unhealthy_Days'),\n",
       " (0.0004056616446691789, 'year'),\n",
       " (0.0002634726468973043, 'Year')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n",
    "\n",
    "# shows the features most likely to make good predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 2: New Features\n",
    "## Comparing Ambulatory Discharges and Ambulatory Visits to Medicare Part B Beneficiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees', 'average_diabetic_enrollees_blood_lipids_test']]\n",
    "y_data2 = data_all[['beneficiaries_part_b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split: \n",
    "<br>\n",
    "Use part of our data to train the algorithm, and part of it to evaluate how well the algorithm does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = y_data\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees</th>\n",
       "      <th>average_diabetic_enrollees_blood_lipids_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>40.7</td>\n",
       "      <td>79.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>67.8</td>\n",
       "      <td>76.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>76.4</td>\n",
       "      <td>80.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>39.8</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>51.7</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees  \\\n",
       "539                                                40.7                    \n",
       "2919                                               67.8                    \n",
       "26                                                 76.4                    \n",
       "3190                                               39.8                    \n",
       "3152                                               51.7                    \n",
       "\n",
       "      average_diabetic_enrollees_blood_lipids_test  \n",
       "539                                           79.3  \n",
       "2919                                          76.7  \n",
       "26                                            80.3  \n",
       "3190                                          69.0  \n",
       "3152                                          72.1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[211 101 101 ... 237  51  40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7805355976485957\n",
      "Testing Data Score: 0.7441253263707572\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         6\n",
      "           3       1.00      1.00      1.00         6\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       1.00      1.00      1.00         6\n",
      "           6       0.46      1.00      0.63         6\n",
      "           7       0.50      1.00      0.67         7\n",
      "           8       0.00      0.00      0.00         7\n",
      "           9       1.00      1.00      1.00         6\n",
      "          10       1.00      1.00      1.00         6\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       0.46      1.00      0.63         6\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       0.00      0.00      0.00         7\n",
      "          15       0.00      0.00      0.00         7\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       1.00      1.00      1.00         6\n",
      "          18       1.00      1.00      1.00         6\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       1.00      1.00      1.00         6\n",
      "          21       1.00      1.00      1.00         6\n",
      "          22       1.00      1.00      1.00         6\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.00      0.00      0.00         7\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       1.00      1.00      1.00         6\n",
      "          27       1.00      1.00      1.00         6\n",
      "          28       1.00      1.00      1.00         6\n",
      "          29       0.46      1.00      0.63         6\n",
      "          30       0.30      1.00      0.46         6\n",
      "          31       0.00      0.00      0.00         7\n",
      "          32       0.30      1.00      0.46         6\n",
      "          33       1.00      1.00      1.00         6\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.46      1.00      0.63         6\n",
      "          36       0.00      0.00      0.00         7\n",
      "          37       1.00      1.00      1.00         6\n",
      "          38       1.00      1.00      1.00         6\n",
      "          39       1.00      1.00      1.00         6\n",
      "          40       1.00      1.00      1.00         6\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       1.00      1.00      1.00         6\n",
      "          43       0.46      1.00      0.63         6\n",
      "          44       1.00      1.00      1.00         6\n",
      "          45       1.00      1.00      1.00         6\n",
      "          46       0.00      0.00      0.00         7\n",
      "          47       1.00      1.00      1.00         6\n",
      "          48       1.00      1.00      1.00         6\n",
      "          49       1.00      1.00      1.00         6\n",
      "          50       0.00      0.00      0.00         7\n",
      "          51       1.00      1.00      1.00         6\n",
      "          52       1.00      1.00      1.00         6\n",
      "          53       1.00      1.00      1.00         6\n",
      "          54       1.00      1.00      1.00         6\n",
      "          55       1.00      1.00      1.00         6\n",
      "          56       1.00      1.00      1.00         6\n",
      "          57       0.46      1.00      0.63         6\n",
      "          58       1.00      1.00      1.00         6\n",
      "          59       1.00      1.00      1.00         6\n",
      "          60       1.00      1.00      1.00         6\n",
      "          61       1.00      1.00      1.00         6\n",
      "          62       1.00      1.00      1.00         7\n",
      "          63       1.00      1.00      1.00         6\n",
      "          64       1.00      1.00      1.00         6\n",
      "          65       1.00      1.00      1.00         6\n",
      "          66       1.00      1.00      1.00         6\n",
      "          67       1.00      1.00      1.00         6\n",
      "          68       1.00      1.00      1.00         6\n",
      "          69       1.00      1.00      1.00         6\n",
      "          70       0.00      0.00      0.00         7\n",
      "          71       1.00      1.00      1.00         6\n",
      "          72       0.00      0.00      0.00         7\n",
      "          73       1.00      1.00      1.00         7\n",
      "          74       0.00      0.00      0.00         7\n",
      "          75       1.00      1.00      1.00         6\n",
      "          76       1.00      1.00      1.00         6\n",
      "          77       1.00      1.00      1.00         6\n",
      "          78       0.00      0.00      0.00         7\n",
      "          79       0.22      1.00      0.36         6\n",
      "          80       1.00      1.00      1.00         6\n",
      "          81       0.46      1.00      0.63         6\n",
      "          82       1.00      1.00      1.00         6\n",
      "          83       1.00      1.00      1.00         6\n",
      "          84       1.00      1.00      1.00         6\n",
      "          85       0.46      1.00      0.63         6\n",
      "          86       1.00      1.00      1.00         6\n",
      "          87       1.00      1.00      1.00         6\n",
      "          88       1.00      1.00      1.00         6\n",
      "          89       1.00      1.00      1.00         6\n",
      "          90       0.30      1.00      0.46         6\n",
      "          91       1.00      1.00      1.00         6\n",
      "          92       0.46      1.00      0.63         6\n",
      "          93       0.46      1.00      0.63         6\n",
      "          94       0.30      1.00      0.46         6\n",
      "          95       0.46      1.00      0.63         6\n",
      "          96       1.00      1.00      1.00         6\n",
      "          97       1.00      1.00      1.00         7\n",
      "          98       0.00      0.00      0.00         7\n",
      "          99       0.00      0.00      0.00         7\n",
      "         100       1.00      1.00      1.00         6\n",
      "         101       1.00      1.00      1.00         6\n",
      "         102       0.00      0.00      0.00         7\n",
      "         103       1.00      1.00      1.00         6\n",
      "         104       1.00      1.00      1.00         6\n",
      "         105       1.00      1.00      1.00         6\n",
      "         106       1.00      1.00      1.00         6\n",
      "         107       1.00      1.00      1.00         6\n",
      "         108       0.46      1.00      0.63         6\n",
      "         109       0.00      0.00      0.00         7\n",
      "         110       1.00      1.00      1.00         6\n",
      "         111       0.30      1.00      0.46         6\n",
      "         112       0.00      0.00      0.00         7\n",
      "         113       0.00      0.00      0.00         7\n",
      "         114       1.00      1.00      1.00         6\n",
      "         115       1.00      1.00      1.00         6\n",
      "         116       0.00      0.00      0.00         7\n",
      "         117       0.00      0.00      0.00         7\n",
      "         118       1.00      1.00      1.00         6\n",
      "         119       1.00      1.00      1.00         6\n",
      "         120       0.46      1.00      0.63         6\n",
      "         121       1.00      1.00      1.00         6\n",
      "         122       1.00      1.00      1.00         6\n",
      "         123       1.00      1.00      1.00         6\n",
      "         124       1.00      1.00      1.00         6\n",
      "         125       1.00      1.00      1.00         6\n",
      "         126       0.00      0.00      0.00         7\n",
      "         127       1.00      1.00      1.00         6\n",
      "         128       1.00      1.00      1.00         6\n",
      "         129       1.00      1.00      1.00         6\n",
      "         130       1.00      1.00      1.00         6\n",
      "         131       1.00      1.00      1.00         7\n",
      "         132       1.00      1.00      1.00         6\n",
      "         133       1.00      1.00      1.00         6\n",
      "         134       1.00      1.00      1.00         6\n",
      "         135       1.00      1.00      1.00         6\n",
      "         136       1.00      1.00      1.00         6\n",
      "         137       1.00      1.00      1.00         6\n",
      "         138       1.00      1.00      1.00         6\n",
      "         139       1.00      1.00      1.00         7\n",
      "         140       0.00      0.00      0.00         7\n",
      "         141       0.00      0.00      0.00         7\n",
      "         142       1.00      1.00      1.00         6\n",
      "         143       0.46      1.00      0.63         6\n",
      "         144       0.00      0.00      0.00         7\n",
      "         145       1.00      1.00      1.00         6\n",
      "         146       1.00      1.00      1.00         6\n",
      "         147       1.00      1.00      1.00         6\n",
      "         148       1.00      1.00      1.00         6\n",
      "         149       1.00      1.00      1.00         6\n",
      "         150       0.46      1.00      0.63         6\n",
      "         151       1.00      1.00      1.00         6\n",
      "         152       0.46      1.00      0.63         6\n",
      "         153       1.00      1.00      1.00         6\n",
      "         154       1.00      1.00      1.00         6\n",
      "         155       1.00      1.00      1.00         6\n",
      "         156       1.00      1.00      1.00         6\n",
      "         157       0.00      0.00      0.00         7\n",
      "         158       1.00      1.00      1.00         6\n",
      "         159       0.00      0.00      0.00         7\n",
      "         160       0.22      1.00      0.36         6\n",
      "         161       0.46      1.00      0.63         6\n",
      "         162       0.46      1.00      0.63         6\n",
      "         163       1.00      1.00      1.00         6\n",
      "         164       0.00      0.00      0.00         7\n",
      "         165       0.46      1.00      0.63         6\n",
      "         166       1.00      1.00      1.00         6\n",
      "         167       0.00      0.00      0.00         7\n",
      "         168       1.00      1.00      1.00         6\n",
      "         169       0.30      1.00      0.46         6\n",
      "         170       1.00      1.00      1.00         6\n",
      "         171       1.00      1.00      1.00         6\n",
      "         172       0.46      1.00      0.63         6\n",
      "         173       0.00      0.00      0.00         7\n",
      "         174       0.30      1.00      0.46         6\n",
      "         175       0.00      0.00      0.00         7\n",
      "         176       0.30      1.00      0.46         6\n",
      "         177       1.00      1.00      1.00         6\n",
      "         178       1.00      1.00      1.00         6\n",
      "         179       0.46      1.00      0.63         6\n",
      "         180       1.00      1.00      1.00         6\n",
      "         181       1.00      1.00      1.00         6\n",
      "         182       1.00      1.00      1.00         6\n",
      "         183       0.00      0.00      0.00         7\n",
      "         184       1.00      1.00      1.00         6\n",
      "         185       0.30      1.00      0.46         6\n",
      "         186       1.00      1.00      1.00         6\n",
      "         187       0.46      1.00      0.63         6\n",
      "         188       1.00      1.00      1.00         6\n",
      "         189       1.00      1.00      1.00         6\n",
      "         190       0.00      0.00      0.00         7\n",
      "         191       0.00      0.00      0.00         7\n",
      "         192       1.00      1.00      1.00         6\n",
      "         193       1.00      1.00      1.00         6\n",
      "         194       1.00      1.00      1.00         6\n",
      "         195       1.00      1.00      1.00         6\n",
      "         196       1.00      1.00      1.00         6\n",
      "         197       0.00      0.00      0.00         7\n",
      "         198       0.46      1.00      0.63         6\n",
      "         199       0.00      0.00      0.00         7\n",
      "         200       0.00      0.00      0.00         7\n",
      "         201       1.00      1.00      1.00         6\n",
      "         202       1.00      1.00      1.00         6\n",
      "         203       1.00      1.00      1.00         6\n",
      "         204       1.00      1.00      1.00         6\n",
      "         205       0.00      0.00      0.00         7\n",
      "         206       1.00      1.00      1.00         6\n",
      "         207       0.00      0.00      0.00         7\n",
      "         208       0.46      1.00      0.63         6\n",
      "         209       1.00      1.00      1.00         6\n",
      "         210       1.00      1.00      1.00         6\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       1.00      1.00      1.00         6\n",
      "         213       0.46      1.00      0.63         6\n",
      "         214       0.00      0.00      0.00         7\n",
      "         215       1.00      1.00      1.00         6\n",
      "         216       1.00      1.00      1.00         6\n",
      "         217       0.00      0.00      0.00         7\n",
      "         218       1.00      1.00      1.00         6\n",
      "         219       0.46      1.00      0.63         6\n",
      "         220       1.00      1.00      1.00         6\n",
      "         221       1.00      1.00      1.00         6\n",
      "         222       0.00      0.00      0.00         7\n",
      "         223       0.46      1.00      0.63         6\n",
      "         224       0.00      0.00      0.00         7\n",
      "         225       0.00      0.00      0.00         7\n",
      "         226       0.30      1.00      0.46         6\n",
      "         227       1.00      1.00      1.00         6\n",
      "         228       1.00      1.00      1.00         6\n",
      "         229       1.00      1.00      1.00         6\n",
      "         230       1.00      1.00      1.00         6\n",
      "         231       1.00      1.00      1.00         6\n",
      "         232       0.46      1.00      0.63         6\n",
      "         233       1.00      1.00      1.00         6\n",
      "         234       0.00      0.00      0.00         7\n",
      "         235       0.46      1.00      0.63         6\n",
      "         236       0.00      0.00      0.00         7\n",
      "         237       1.00      1.00      1.00         6\n",
      "         238       0.00      0.00      0.00         7\n",
      "         239       1.00      1.00      1.00         6\n",
      "         240       1.00      1.00      1.00         6\n",
      "         241       0.00      0.00      0.00         7\n",
      "         242       0.00      0.00      0.00         7\n",
      "         243       1.00      1.00      1.00         6\n",
      "         244       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.74      1532\n",
      "   macro avg       0.67      0.77      0.70      1532\n",
      "weighted avg       0.65      0.74      0.67      1532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))\n",
    "\n",
    "# These features show higher precision scores - but only one dataset is being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 3: New \"y\" Data, and Features\n",
    "## Comparing Comparing Pollutant (Nitrogen Dioxide and Sulfur Dioxide) Levels to Household Income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State',\n",
       " 'year',\n",
       " 'state_name',\n",
       " 'Population',\n",
       " 'HHI',\n",
       " 'PovertyRate',\n",
       " 'state_id',\n",
       " 'beneficiaries_part_b',\n",
       " 'one_ambulatory_visit',\n",
       " 'diabetic_enrollees_age_65_to_75',\n",
       " 'average_diabetic_enrollees_hemoglobin_a1c_test',\n",
       " 'average_diabetic_enrollees_eye_exam',\n",
       " 'average_diabetic_enrollees_blood_lipids_test',\n",
       " 'average_female_enrollees_age_67_to_69',\n",
       " 'average_female_age_67_to_69_mammogram',\n",
       " 'beneficiaries_part_a_eligible',\n",
       " 'leg_amputations_per_1000_enrollees',\n",
       " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees',\n",
       " 'Days_with_AQI',\n",
       " 'Year',\n",
       " 'Good_Days',\n",
       " 'Moderate_Days',\n",
       " 'Unhealthy_Days',\n",
       " 'Very_Unhealthy_Days',\n",
       " 'Hazardous_Days',\n",
       " 'Days_CO',\n",
       " 'Days_NO2',\n",
       " 'Days_Ozone',\n",
       " 'Days_SO2',\n",
       " 'Days_PM2.5',\n",
       " 'Days_PM10']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify column names \n",
    "\n",
    "list(data_all.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['Days_NO2', 'Days_SO2']]\n",
    "y_data = data_all[['HHI']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = y_data\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days_NO2</th>\n",
       "      <th>Days_SO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>9.67</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>35.06</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>6.76</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>1.33</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Days_NO2  Days_SO2\n",
       "4995      9.67      0.00\n",
       "5559     35.06      0.97\n",
       "611       6.76      0.09\n",
       "3422      0.80      0.00\n",
       "4637      1.33      0.00"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 61 140 171 ... 158 117 158]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.07968647942521227\n",
      "Testing Data Score: 0.05156657963446475\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.09      0.67      0.16         6\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         7\n",
      "           9       0.00      0.00      0.00         6\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.06      0.50      0.11         6\n",
      "          12       0.00      0.00      0.00         6\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         7\n",
      "          15       0.13      0.33      0.19         6\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00         7\n",
      "          18       0.04      0.17      0.06         6\n",
      "          19       0.00      0.00      0.00         6\n",
      "          20       0.00      0.00      0.00         7\n",
      "          21       0.00      0.00      0.00         7\n",
      "          22       0.00      0.00      0.00         6\n",
      "          23       0.00      0.00      0.00         6\n",
      "          24       0.00      0.00      0.00         6\n",
      "          25       0.00      0.00      0.00         6\n",
      "          26       0.00      0.00      0.00         6\n",
      "          27       0.14      0.17      0.15         6\n",
      "          28       0.00      0.00      0.00         6\n",
      "          29       0.00      0.00      0.00         6\n",
      "          30       0.00      0.00      0.00         6\n",
      "          31       0.00      0.00      0.00         6\n",
      "          32       0.00      0.00      0.00         6\n",
      "          33       0.00      0.00      0.00         6\n",
      "          34       0.00      0.00      0.00         6\n",
      "          35       0.03      0.17      0.05         6\n",
      "          36       0.00      0.00      0.00         6\n",
      "          37       0.00      0.00      0.00         7\n",
      "          38       0.00      0.00      0.00         6\n",
      "          39       0.00      0.00      0.00         6\n",
      "          40       0.00      0.00      0.00         6\n",
      "          41       0.00      0.00      0.00         6\n",
      "          42       0.00      0.00      0.00         6\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00         6\n",
      "          46       0.00      0.00      0.00         6\n",
      "          47       0.00      0.00      0.00         6\n",
      "          48       0.00      0.00      0.00         7\n",
      "          49       0.00      0.00      0.00         6\n",
      "          50       0.00      0.00      0.00         7\n",
      "          51       0.00      0.00      0.00         6\n",
      "          52       0.00      0.00      0.00         7\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.00      0.00      0.00         7\n",
      "          55       0.06      0.17      0.09         6\n",
      "          56       0.18      0.50      0.26         6\n",
      "          57       0.00      0.00      0.00         7\n",
      "          58       0.00      0.00      0.00         7\n",
      "          59       0.00      0.00      0.00         7\n",
      "          60       0.00      0.00      0.00         6\n",
      "          61       0.00      0.00      0.00         6\n",
      "          62       0.04      0.17      0.07         6\n",
      "          63       0.00      0.00      0.00         7\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.00      0.00      0.00         6\n",
      "          66       0.00      0.00      0.00         6\n",
      "          67       0.13      0.33      0.19         6\n",
      "          68       0.00      0.00      0.00         6\n",
      "          69       0.00      0.00      0.00         6\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.00      0.00         7\n",
      "          72       0.00      0.00      0.00         7\n",
      "          73       0.00      0.00      0.00         6\n",
      "          74       0.00      0.00      0.00         7\n",
      "          75       0.00      0.00      0.00         6\n",
      "          76       0.00      0.00      0.00         6\n",
      "          77       0.00      0.00      0.00         6\n",
      "          78       0.00      0.00      0.00         6\n",
      "          79       0.00      0.00      0.00         6\n",
      "          80       0.10      0.33      0.15         6\n",
      "          81       0.00      0.00      0.00         6\n",
      "          82       0.07      0.17      0.10         6\n",
      "          83       0.00      0.00      0.00         6\n",
      "          84       0.00      0.00      0.00         6\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         6\n",
      "          87       0.00      0.00      0.00         7\n",
      "          88       0.00      0.00      0.00         7\n",
      "          89       0.00      0.00      0.00         7\n",
      "          90       0.00      0.00      0.00         6\n",
      "          91       0.00      0.00      0.00         6\n",
      "          92       0.00      0.00      0.00         7\n",
      "          93       0.00      0.00      0.00         6\n",
      "          94       0.00      0.00      0.00         6\n",
      "          95       0.00      0.00      0.00         6\n",
      "          96       0.00      0.00      0.00         6\n",
      "          97       0.00      0.00      0.00         6\n",
      "          98       0.00      0.00      0.00         6\n",
      "          99       0.00      0.00      0.00         7\n",
      "         100       0.00      0.00      0.00         6\n",
      "         101       0.09      0.17      0.12         6\n",
      "         102       0.00      0.00      0.00         7\n",
      "         103       0.00      0.00      0.00         7\n",
      "         104       0.03      0.17      0.05         6\n",
      "         105       0.00      0.00      0.00         6\n",
      "         106       0.00      0.00      0.00         7\n",
      "         107       0.00      0.00      0.00         7\n",
      "         108       0.00      0.00      0.00         6\n",
      "         109       0.22      0.33      0.27         6\n",
      "         110       0.10      0.33      0.15         6\n",
      "         111       0.00      0.00      0.00         6\n",
      "         112       0.00      0.00      0.00         6\n",
      "         113       0.00      0.00      0.00         6\n",
      "         114       0.00      0.00      0.00         6\n",
      "         115       0.00      0.00      0.00         6\n",
      "         116       0.00      0.00      0.00         7\n",
      "         117       0.00      0.00      0.00         6\n",
      "         118       0.00      0.00      0.00         6\n",
      "         119       0.29      0.33      0.31         6\n",
      "         120       0.00      0.00      0.00         6\n",
      "         121       0.00      0.00      0.00         7\n",
      "         122       0.00      0.00      0.00         6\n",
      "         123       0.00      0.00      0.00         6\n",
      "         124       0.00      0.00      0.00         6\n",
      "         125       0.00      0.00      0.00         6\n",
      "         126       0.04      0.33      0.08         6\n",
      "         127       0.00      0.00      0.00         6\n",
      "         128       0.00      0.00      0.00         6\n",
      "         129       0.00      0.00      0.00         7\n",
      "         130       0.00      0.00      0.00         7\n",
      "         131       0.02      0.62      0.04        13\n",
      "         132       0.00      0.00      0.00         7\n",
      "         133       0.00      0.00      0.00         6\n",
      "         134       0.06      0.67      0.11         6\n",
      "         135       0.00      0.00      0.00         7\n",
      "         136       0.00      0.00      0.00         6\n",
      "         137       0.00      0.00      0.00         6\n",
      "         138       0.00      0.00      0.00         6\n",
      "         139       0.00      0.00      0.00         6\n",
      "         140       0.13      0.33      0.19         6\n",
      "         141       0.05      0.17      0.07         6\n",
      "         142       0.00      0.00      0.00         6\n",
      "         143       0.00      0.00      0.00         6\n",
      "         144       0.00      0.00      0.00         6\n",
      "         145       0.00      0.00      0.00         6\n",
      "         146       0.00      0.00      0.00         6\n",
      "         147       0.04      0.17      0.06         6\n",
      "         148       0.00      0.00      0.00         6\n",
      "         149       0.00      0.00      0.00         6\n",
      "         150       0.00      0.00      0.00         7\n",
      "         151       0.00      0.00      0.00         6\n",
      "         152       0.00      0.00      0.00         7\n",
      "         153       0.00      0.00      0.00         6\n",
      "         154       0.00      0.00      0.00         6\n",
      "         155       0.00      0.00      0.00         6\n",
      "         156       0.00      0.00      0.00         6\n",
      "         157       0.00      0.00      0.00         6\n",
      "         158       0.00      0.00      0.00         7\n",
      "         159       0.00      0.00      0.00         6\n",
      "         160       0.09      0.33      0.14         6\n",
      "         161       0.00      0.00      0.00         7\n",
      "         162       0.00      0.00      0.00         6\n",
      "         163       0.00      0.00      0.00         6\n",
      "         164       0.17      0.50      0.25         6\n",
      "         165       0.00      0.00      0.00         6\n",
      "         166       0.00      0.00      0.00         6\n",
      "         167       0.00      0.00      0.00         7\n",
      "         168       0.00      0.00      0.00         6\n",
      "         169       0.02      0.17      0.03         6\n",
      "         170       0.00      0.00      0.00         7\n",
      "         171       0.07      0.33      0.12         6\n",
      "         172       0.00      0.00      0.00         6\n",
      "         173       0.05      0.33      0.09         6\n",
      "         174       0.00      0.00      0.00         6\n",
      "         175       0.00      0.00      0.00         7\n",
      "         176       0.00      0.00      0.00         6\n",
      "         177       0.00      0.00      0.00         6\n",
      "         178       0.09      0.83      0.17         6\n",
      "         179       0.00      0.00      0.00         6\n",
      "         180       0.00      0.00      0.00         7\n",
      "         181       0.00      0.00      0.00         6\n",
      "         182       0.11      0.33      0.16         6\n",
      "         183       0.00      0.00      0.00         6\n",
      "         184       0.00      0.00      0.00         6\n",
      "         185       0.00      0.00      0.00         6\n",
      "         186       0.00      0.00      0.00         6\n",
      "         187       0.00      0.00      0.00         6\n",
      "         188       0.00      0.00      0.00         7\n",
      "         189       0.00      0.00      0.00         7\n",
      "         190       0.00      0.00      0.00         7\n",
      "         191       0.00      0.00      0.00         6\n",
      "         192       0.00      0.00      0.00         7\n",
      "         193       0.00      0.00      0.00         6\n",
      "         194       0.00      0.00      0.00         6\n",
      "         195       0.00      0.00      0.00         6\n",
      "         196       0.00      0.00      0.00         6\n",
      "         197       0.00      0.00      0.00         6\n",
      "         198       0.00      0.00      0.00         6\n",
      "         199       0.00      0.00      0.00         7\n",
      "         200       0.09      0.33      0.14         6\n",
      "         201       0.00      0.00      0.00         6\n",
      "         202       0.00      0.00      0.00         7\n",
      "         203       0.00      0.00      0.00         7\n",
      "         204       0.00      0.00      0.00         7\n",
      "         205       0.00      0.00      0.00         6\n",
      "         206       0.00      0.00      0.00         6\n",
      "         207       0.00      0.00      0.00         6\n",
      "         208       0.07      0.33      0.11         6\n",
      "         209       0.00      0.00      0.00         7\n",
      "         210       0.00      0.00      0.00         6\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       0.00      0.00      0.00         6\n",
      "         213       0.00      0.00      0.00         6\n",
      "         214       0.00      0.00      0.00         7\n",
      "         215       0.00      0.00      0.00         7\n",
      "         216       0.00      0.00      0.00         6\n",
      "         217       0.00      0.00      0.00         6\n",
      "         218       0.00      0.00      0.00         6\n",
      "         219       0.00      0.00      0.00         6\n",
      "         220       0.00      0.00      0.00         6\n",
      "         221       0.08      0.17      0.11         6\n",
      "         222       0.00      0.00      0.00         6\n",
      "         223       0.00      0.00      0.00         6\n",
      "         224       0.00      0.00      0.00         7\n",
      "         225       0.00      0.00      0.00         6\n",
      "         226       0.18      0.50      0.26         6\n",
      "         227       0.00      0.00      0.00         6\n",
      "         228       0.00      0.00      0.00         6\n",
      "         229       0.00      0.00      0.00         7\n",
      "         230       0.00      0.00      0.00         7\n",
      "         231       0.03      0.50      0.06         6\n",
      "         232       0.00      0.00      0.00         7\n",
      "         233       0.00      0.00      0.00         6\n",
      "         234       0.00      0.00      0.00         6\n",
      "         235       0.00      0.00      0.00         6\n",
      "         236       0.00      0.00      0.00         7\n",
      "         237       0.30      0.50      0.37         6\n",
      "         238       0.00      0.00      0.00         6\n",
      "         239       0.00      0.00      0.00         6\n",
      "         240       0.00      0.00      0.00         7\n",
      "         241       0.00      0.00      0.00         6\n",
      "         242       0.00      0.00      0.00         6\n",
      "         243       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.05      1532\n",
      "   macro avg       0.01      0.05      0.02      1532\n",
      "weighted avg       0.01      0.05      0.02      1532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))\n",
    "\n",
    "# low precision scores indicate we need different data to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_all[\"HHI\"]\n",
    "target_names = data_all[\"HHI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all.drop(\"HHI\", axis=1)\n",
    "data = data.drop(\"state_name\", axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.21296702929481867, 'PovertyRate'),\n",
       " (0.2120303378174101, 'Population'),\n",
       " (0.18237146305387789, 'year'),\n",
       " (0.0299812148266366, 'state_id'),\n",
       " (0.02843655083215746, 'State'),\n",
       " (0.026586220688208508, 'beneficiaries_part_b'),\n",
       " (0.025224591560444112, 'average_diabetic_enrollees_eye_exam'),\n",
       " (0.02265009151387608, 'diabetic_enrollees_age_65_to_75'),\n",
       " (0.020465055197379418, 'average_female_age_67_to_69_mammogram'),\n",
       " (0.020039362297317398, 'Days_PM10'),\n",
       " (0.019733676578383867, 'average_female_enrollees_age_67_to_69'),\n",
       " (0.017810979027268064, 'one_ambulatory_visit'),\n",
       " (0.0177284100722464, 'Days_PM2.5'),\n",
       " (0.017484002644516255, 'Days_Ozone'),\n",
       " (0.017467958905004848, 'average_diabetic_enrollees_hemoglobin_a1c_test'),\n",
       " (0.01669010919474414, 'average_diabetic_enrollees_blood_lipids_test'),\n",
       " (0.01611780454455719, 'Days_SO2'),\n",
       " (0.014593973943869666, 'Days_NO2'),\n",
       " (0.014383744368862087, 'beneficiaries_part_a_eligible'),\n",
       " (0.014126448497382304, 'Days_with_AQI'),\n",
       " (0.009360714863645715, 'Good_Days'),\n",
       " (0.008491138931334458, 'Moderate_Days'),\n",
       " (0.007662710578611935, 'leg_amputations_per_1000_enrollees'),\n",
       " (0.0076041741514392,\n",
       "  'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees'),\n",
       " (0.005930612923595568, 'Hazardous_Days'),\n",
       " (0.005453431076667871, 'Unhealthy_Days'),\n",
       " (0.003598021600405776, 'Year'),\n",
       " (0.0032088214504809674, 'Days_CO'),\n",
       " (0.001801349564857639, 'Very_Unhealthy_Days')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n",
    "\n",
    "# shows the features most likely to make good predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 4: New Features\n",
    "## Comparing Income and Part B Beneficiaries to Poverty Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['beneficiaries_part_b', 'HHI']]\n",
    "y_data = data_all[['PovertyRate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = y_data\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "      <th>HHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>1331041.0</td>\n",
       "      <td>56576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>637290.0</td>\n",
       "      <td>48393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>1470999.0</td>\n",
       "      <td>59269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>277556.0</td>\n",
       "      <td>58476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>344798.0</td>\n",
       "      <td>70331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      beneficiaries_part_b    HHI\n",
       "1509             1331041.0  56576\n",
       "1634              637290.0  48393\n",
       "3981             1470999.0  59269\n",
       "2760              277556.0  58476\n",
       "857               344798.0  70331"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7 113 113 ...  75  44  29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6969301110385369\n",
      "Testing Data Score: 0.6488250652741514\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.30      1.00      0.46         6\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       1.00      1.00      1.00         6\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       0.46      1.00      0.63         6\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       1.00      1.00      1.00         6\n",
      "           9       1.00      1.00      1.00         6\n",
      "          10       1.00      1.00      1.00         6\n",
      "          11       0.00      0.00      0.00         7\n",
      "          12       0.46      1.00      0.63         6\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       0.00      0.00      0.00         7\n",
      "          15       1.00      1.00      1.00         6\n",
      "          16       0.46      1.00      0.63         6\n",
      "          17       1.00      1.00      1.00         6\n",
      "          18       0.00      0.00      0.00         7\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       1.00      1.00      1.00         6\n",
      "          21       0.00      0.00      0.00         7\n",
      "          22       0.46      1.00      0.63         6\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.46      1.00      0.63         6\n",
      "          25       0.57      0.67      0.62         6\n",
      "          26       1.00      1.00      1.00         6\n",
      "          27       0.22      1.00      0.36         6\n",
      "          28       0.25      0.17      0.20         6\n",
      "          29       0.38      0.50      0.43         6\n",
      "          30       0.00      0.00      0.00         7\n",
      "          31       0.46      1.00      0.63         6\n",
      "          32       0.60      0.50      0.55         6\n",
      "          33       1.00      1.00      1.00         6\n",
      "          34       1.00      1.00      1.00         6\n",
      "          35       0.00      0.00      0.00         7\n",
      "          36       0.00      0.00      0.00         7\n",
      "          37       1.00      1.00      1.00         6\n",
      "          38       1.00      1.00      1.00         6\n",
      "          39       0.00      0.00      0.00         7\n",
      "          40       0.46      1.00      0.63         6\n",
      "          41       1.00      1.00      1.00         6\n",
      "          42       0.00      0.00      0.00         7\n",
      "          43       0.00      0.00      0.00         7\n",
      "          44       1.00      1.00      1.00         6\n",
      "          45       1.00      1.00      1.00         6\n",
      "          46       1.00      1.00      1.00         6\n",
      "          47       0.33      0.33      0.33         6\n",
      "          48       1.00      1.00      1.00         6\n",
      "          49       0.33      0.33      0.33         6\n",
      "          50       1.00      1.00      1.00         6\n",
      "          51       1.00      1.00      1.00         6\n",
      "          52       0.75      1.00      0.86         6\n",
      "          53       0.46      1.00      0.63         6\n",
      "          54       1.00      1.00      1.00         6\n",
      "          55       1.00      1.00      1.00         6\n",
      "          56       1.00      1.00      1.00         6\n",
      "          57       1.00      1.00      1.00         6\n",
      "          58       0.43      1.00      0.60         6\n",
      "          59       0.00      0.00      0.00         7\n",
      "          60       0.46      1.00      0.63         6\n",
      "          61       1.00      1.00      1.00         6\n",
      "          62       1.00      1.00      1.00         6\n",
      "          63       1.00      1.00      1.00         6\n",
      "          64       1.00      1.00      1.00         6\n",
      "          65       1.00      1.00      1.00         6\n",
      "          66       1.00      1.00      1.00         6\n",
      "          67       0.46      1.00      0.63         6\n",
      "          68       1.00      1.00      1.00         6\n",
      "          69       0.46      1.00      0.63         6\n",
      "          70       0.00      0.00      0.00         7\n",
      "          71       1.00      1.00      1.00         6\n",
      "          72       0.00      0.00      0.00         7\n",
      "          73       1.00      1.00      1.00         6\n",
      "          74       0.00      0.00      0.00         7\n",
      "          75       1.00      1.00      1.00         6\n",
      "          76       0.00      0.00      0.00         7\n",
      "          77       1.00      1.00      1.00         6\n",
      "          78       0.86      1.00      0.92         6\n",
      "          79       0.00      0.00      0.00         7\n",
      "          80       0.00      0.00      0.00         7\n",
      "          81       0.00      0.00      0.00         7\n",
      "          82       1.00      1.00      1.00         6\n",
      "          83       0.30      1.00      0.46         6\n",
      "          84       1.00      1.00      1.00         6\n",
      "          85       0.00      0.00      0.00         7\n",
      "          86       1.00      1.00      1.00         6\n",
      "          87       0.42      0.83      0.56         6\n",
      "          88       0.83      0.83      0.83         6\n",
      "          89       1.00      1.00      1.00         6\n",
      "          90       0.46      1.00      0.63         6\n",
      "          91       0.46      1.00      0.63         6\n",
      "          92       1.00      1.00      1.00         6\n",
      "          93       0.00      0.00      0.00         7\n",
      "          94       0.00      0.00      0.00         7\n",
      "          95       0.30      1.00      0.46         6\n",
      "          96       0.00      0.00      0.00         7\n",
      "          97       0.46      1.00      0.63         6\n",
      "          98       0.45      0.83      0.59         6\n",
      "          99       1.00      1.00      1.00         6\n",
      "         100       1.00      1.00      1.00         6\n",
      "         101       1.00      1.00      1.00         6\n",
      "         102       1.00      1.00      1.00         6\n",
      "         103       0.46      1.00      0.63         6\n",
      "         104       0.46      1.00      0.63         6\n",
      "         105       1.00      1.00      1.00         6\n",
      "         106       1.00      1.00      1.00         6\n",
      "         107       1.00      1.00      1.00         6\n",
      "         108       0.23      0.50      0.32         6\n",
      "         109       0.00      0.00      0.00         7\n",
      "         110       0.00      0.00      0.00         7\n",
      "         111       0.00      0.00      0.00         7\n",
      "         112       1.00      1.00      1.00         6\n",
      "         113       1.00      1.00      1.00         6\n",
      "         114       0.00      0.00      0.00         7\n",
      "         115       1.00      1.00      1.00         6\n",
      "         116       1.00      1.00      1.00         6\n",
      "         117       0.46      1.00      0.63         6\n",
      "         118       0.46      1.00      0.63         6\n",
      "         119       0.18      0.33      0.24         6\n",
      "         120       1.00      1.00      1.00         6\n",
      "         121       0.00      0.00      0.00         7\n",
      "         122       1.00      0.67      0.80         6\n",
      "         123       0.46      1.00      0.63         6\n",
      "         124       0.00      0.00      0.00         7\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.75      1.00      0.86         6\n",
      "         127       1.00      1.00      1.00         6\n",
      "         128       0.00      0.00      0.00         7\n",
      "         129       0.00      0.00      0.00         7\n",
      "         130       1.00      1.00      1.00         6\n",
      "         131       1.00      1.00      1.00         6\n",
      "         132       0.50      1.00      0.67         6\n",
      "         133       0.75      1.00      0.86         6\n",
      "         134       1.00      1.00      1.00         6\n",
      "         135       0.67      1.00      0.80         6\n",
      "         136       0.46      1.00      0.63         6\n",
      "         137       0.60      1.00      0.75         6\n",
      "         138       0.00      0.00      0.00         7\n",
      "         139       1.00      1.00      1.00         6\n",
      "         140       1.00      1.00      1.00         6\n",
      "         141       1.00      1.00      1.00         6\n",
      "         142       0.36      0.83      0.50         6\n",
      "         143       0.00      0.00      0.00         7\n",
      "         144       0.19      0.67      0.30         6\n",
      "         145       1.00      1.00      1.00         6\n",
      "         146       1.00      1.00      1.00         6\n",
      "         147       1.00      1.00      1.00         6\n",
      "         148       1.00      1.00      1.00         6\n",
      "         149       0.67      1.00      0.80         6\n",
      "         150       0.22      0.33      0.27         6\n",
      "         151       0.00      0.00      0.00         7\n",
      "         152       0.00      0.00      0.00         7\n",
      "         153       0.00      0.00      0.00         7\n",
      "         154       0.46      1.00      0.63         6\n",
      "         155       0.44      0.67      0.53         6\n",
      "         156       0.00      0.00      0.00         7\n",
      "         157       1.00      1.00      1.00         6\n",
      "         158       1.00      1.00      1.00         6\n",
      "         159       1.00      1.00      1.00         6\n",
      "         160       0.43      1.00      0.60         6\n",
      "         161       0.75      1.00      0.86         6\n",
      "         162       0.60      0.50      0.55         6\n",
      "         163       0.00      0.00      0.00         6\n",
      "         164       0.55      1.00      0.71         6\n",
      "         165       1.00      1.00      1.00         6\n",
      "         166       0.46      1.00      0.63         6\n",
      "         167       0.83      0.83      0.83         6\n",
      "         168       0.50      1.00      0.67         6\n",
      "         169       1.00      1.00      1.00         6\n",
      "         170       1.00      0.67      0.80         6\n",
      "         171       0.00      0.00      0.00         7\n",
      "         172       1.00      0.67      0.80         6\n",
      "         173       0.00      0.00      0.00         7\n",
      "         174       0.46      1.00      0.63         6\n",
      "         175       1.00      1.00      1.00         6\n",
      "         176       0.33      0.17      0.22         6\n",
      "         177       1.00      1.00      1.00         6\n",
      "         178       1.00      1.00      1.00         6\n",
      "         179       0.00      0.00      0.00         7\n",
      "         180       1.00      1.00      1.00         6\n",
      "         181       0.25      0.33      0.29         6\n",
      "         182       0.00      0.00      0.00         7\n",
      "         183       0.60      1.00      0.75         6\n",
      "         184       0.75      0.50      0.60         6\n",
      "         185       1.00      0.67      0.80         6\n",
      "         186       1.00      1.00      1.00         6\n",
      "         187       0.33      0.17      0.22         6\n",
      "         188       0.00      0.00      0.00         7\n",
      "         189       1.00      1.00      1.00         6\n",
      "         190       0.33      0.17      0.22         6\n",
      "         191       0.00      0.00      0.00         7\n",
      "         192       0.46      1.00      0.63         6\n",
      "         193       1.00      1.00      1.00         6\n",
      "         194       0.25      0.17      0.20         6\n",
      "         195       0.31      0.67      0.42         6\n",
      "         196       0.00      0.00      0.00         7\n",
      "         197       0.30      0.50      0.37         6\n",
      "         198       0.46      1.00      0.63         6\n",
      "         199       0.75      1.00      0.86         6\n",
      "         200       0.67      1.00      0.80         6\n",
      "         201       0.00      0.00      0.00         7\n",
      "         202       1.00      1.00      1.00         6\n",
      "         203       0.46      1.00      0.63         6\n",
      "         204       0.75      1.00      0.86         6\n",
      "         205       1.00      0.83      0.91         6\n",
      "         206       0.46      1.00      0.63         6\n",
      "         207       0.50      0.50      0.50         6\n",
      "         208       0.21      0.50      0.30         6\n",
      "         209       0.00      0.00      0.00         7\n",
      "         210       0.00      0.00      0.00         7\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       1.00      1.00      1.00         6\n",
      "         213       0.00      0.00      0.00         7\n",
      "         214       0.44      0.67      0.53         6\n",
      "         215       0.50      0.50      0.50         6\n",
      "         216       1.00      1.00      1.00         6\n",
      "         217       1.00      1.00      1.00         6\n",
      "         218       0.36      0.67      0.47         6\n",
      "         219       1.00      1.00      1.00         6\n",
      "         220       0.22      1.00      0.36         6\n",
      "         221       1.00      1.00      1.00         6\n",
      "         222       0.00      0.00      0.00         7\n",
      "         223       0.46      1.00      0.63         6\n",
      "         224       0.00      0.00      0.00         7\n",
      "         225       0.00      0.00      0.00         7\n",
      "         226       0.00      0.00      0.00         7\n",
      "         227       0.75      1.00      0.86         6\n",
      "         228       0.46      1.00      0.63         6\n",
      "         229       0.75      1.00      0.86         6\n",
      "         230       1.00      1.00      1.00         6\n",
      "         231       1.00      1.00      1.00         6\n",
      "         232       0.00      0.00      0.00         7\n",
      "         233       1.00      1.00      1.00         6\n",
      "         234       0.46      1.00      0.63         6\n",
      "         235       0.00      0.00      0.00         7\n",
      "         236       0.00      0.00      0.00         7\n",
      "         237       0.00      0.00      0.00         7\n",
      "         238       0.00      0.00      0.00         7\n",
      "         239       0.22      1.00      0.36         6\n",
      "         240       1.00      1.00      1.00         6\n",
      "         241       1.00      1.00      1.00         6\n",
      "         242       1.00      1.00      1.00         6\n",
      "         243       1.00      1.00      1.00         6\n",
      "         244       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.65      1532\n",
      "   macro avg       0.56      0.68      0.59      1532\n",
      "weighted avg       0.54      0.65      0.57      1532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))\n",
    "\n",
    "# low precision scores indicate we need different data to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_all[\"PovertyRate\"]\n",
    "target_names = data_all[\"PovertyRate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all.drop(\"PovertyRate\", axis=1)\n",
    "data = data.drop(\"state_name\", axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rf = RandomForestClassifier(n_estimators=200)\n",
    "# rf = rf.fit(X_train, y_train)\n",
    "# rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n",
    "\n",
    "# # shows the features most likely to make good predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 5: New Features\n",
    "## Comparing Income, Part B Beneficiaries, and Unhealthy Days\n",
    "## to Poverty Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State',\n",
       " 'year',\n",
       " 'state_name',\n",
       " 'Population',\n",
       " 'HHI',\n",
       " 'PovertyRate',\n",
       " 'state_id',\n",
       " 'beneficiaries_part_b',\n",
       " 'one_ambulatory_visit',\n",
       " 'diabetic_enrollees_age_65_to_75',\n",
       " 'average_diabetic_enrollees_hemoglobin_a1c_test',\n",
       " 'average_diabetic_enrollees_eye_exam',\n",
       " 'average_diabetic_enrollees_blood_lipids_test',\n",
       " 'average_female_enrollees_age_67_to_69',\n",
       " 'average_female_age_67_to_69_mammogram',\n",
       " 'beneficiaries_part_a_eligible',\n",
       " 'leg_amputations_per_1000_enrollees',\n",
       " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees',\n",
       " 'Days_with_AQI',\n",
       " 'Year',\n",
       " 'Good_Days',\n",
       " 'Moderate_Days',\n",
       " 'Unhealthy_Days',\n",
       " 'Very_Unhealthy_Days',\n",
       " 'Hazardous_Days',\n",
       " 'Days_CO',\n",
       " 'Days_NO2',\n",
       " 'Days_Ozone',\n",
       " 'Days_SO2',\n",
       " 'Days_PM2.5',\n",
       " 'Days_PM10']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify column names \n",
    "\n",
    "list(data_all.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['HHI', 'Unhealthy_Days', 'beneficiaries_part_b']]\n",
    "y_data = data_all[['PovertyRate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split: \n",
    "<br>\n",
    "Use part of our data to train the algorithm, and part of it to evaluate how well the algorithm does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = y_data\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHI</th>\n",
       "      <th>Unhealthy_Days</th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>56576</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1331041.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>48393</td>\n",
       "      <td>0.16</td>\n",
       "      <td>637290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>59269</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1470999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>58476</td>\n",
       "      <td>0.05</td>\n",
       "      <td>277556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>70331</td>\n",
       "      <td>1.88</td>\n",
       "      <td>344798.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        HHI  Unhealthy_Days  beneficiaries_part_b\n",
       "1509  56576            0.08             1331041.0\n",
       "1634  48393            0.16              637290.0\n",
       "3981  59269            0.39             1470999.0\n",
       "2760  58476            0.05              277556.0\n",
       "857   70331            1.88              344798.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7 113 113 ...  75  44  29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.5260178532549532\n",
      "Testing Data Score: 0.4510443864229765\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.30      1.00      0.46         6\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       1.00      1.00      1.00         6\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       0.60      1.00      0.75         6\n",
      "           6       0.50      0.50      0.50         6\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       1.00      0.67      0.80         6\n",
      "           9       1.00      0.50      0.67         6\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00         7\n",
      "          12       0.11      0.17      0.13         6\n",
      "          13       0.17      0.33      0.22         6\n",
      "          14       0.00      0.00      0.00         7\n",
      "          15       1.00      1.00      1.00         6\n",
      "          16       0.38      1.00      0.55         6\n",
      "          17       1.00      0.50      0.67         6\n",
      "          18       0.00      0.00      0.00         7\n",
      "          19       0.26      0.83      0.40         6\n",
      "          20       1.00      0.83      0.91         6\n",
      "          21       0.00      0.00      0.00         7\n",
      "          22       0.29      0.83      0.43         6\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.38      0.83      0.53         6\n",
      "          25       0.57      0.67      0.62         6\n",
      "          26       1.00      1.00      1.00         6\n",
      "          27       0.00      0.00      0.00         6\n",
      "          28       0.29      0.33      0.31         6\n",
      "          29       0.43      0.50      0.46         6\n",
      "          30       0.00      0.00      0.00         7\n",
      "          31       0.46      1.00      0.63         6\n",
      "          32       0.60      0.50      0.55         6\n",
      "          33       0.50      0.83      0.62         6\n",
      "          34       0.55      1.00      0.71         6\n",
      "          35       0.17      0.57      0.27         7\n",
      "          36       0.00      0.00      0.00         7\n",
      "          37       1.00      0.83      0.91         6\n",
      "          38       1.00      1.00      1.00         6\n",
      "          39       0.00      0.00      0.00         7\n",
      "          40       0.46      1.00      0.63         6\n",
      "          41       1.00      1.00      1.00         6\n",
      "          42       0.00      0.00      0.00         7\n",
      "          43       0.00      0.00      0.00         7\n",
      "          44       0.75      0.50      0.60         6\n",
      "          45       1.00      1.00      1.00         6\n",
      "          46       1.00      1.00      1.00         6\n",
      "          47       0.33      0.33      0.33         6\n",
      "          48       1.00      1.00      1.00         6\n",
      "          49       0.33      0.33      0.33         6\n",
      "          50       0.50      1.00      0.67         6\n",
      "          51       0.00      0.00      0.00         6\n",
      "          52       0.75      1.00      0.86         6\n",
      "          53       0.40      0.33      0.36         6\n",
      "          54       0.20      1.00      0.33         6\n",
      "          55       0.86      1.00      0.92         6\n",
      "          56       1.00      1.00      1.00         6\n",
      "          57       0.60      1.00      0.75         6\n",
      "          58       0.00      0.00      0.00         6\n",
      "          59       0.00      0.00      0.00         7\n",
      "          60       0.12      0.17      0.14         6\n",
      "          61       0.43      1.00      0.60         6\n",
      "          62       1.00      0.17      0.29         6\n",
      "          63       1.00      0.83      0.91         6\n",
      "          64       0.17      0.33      0.22         6\n",
      "          65       1.00      1.00      1.00         6\n",
      "          66       0.45      0.83      0.59         6\n",
      "          67       0.17      0.17      0.17         6\n",
      "          68       1.00      0.50      0.67         6\n",
      "          69       0.46      1.00      0.63         6\n",
      "          70       0.00      0.00      0.00         7\n",
      "          71       1.00      1.00      1.00         6\n",
      "          72       0.00      0.00      0.00         7\n",
      "          73       1.00      1.00      1.00         6\n",
      "          74       0.00      0.00      0.00         7\n",
      "          75       1.00      1.00      1.00         6\n",
      "          76       0.00      0.00      0.00         7\n",
      "          77       1.00      1.00      1.00         6\n",
      "          78       0.27      1.00      0.43         6\n",
      "          79       0.00      0.00      0.00         7\n",
      "          80       0.00      0.00      0.00         7\n",
      "          81       0.00      0.00      0.00         7\n",
      "          82       1.00      0.83      0.91         6\n",
      "          83       0.30      1.00      0.46         6\n",
      "          84       0.25      1.00      0.40         6\n",
      "          85       0.00      0.00      0.00         7\n",
      "          86       0.25      1.00      0.40         6\n",
      "          87       0.00      0.00      0.00         6\n",
      "          88       0.50      0.33      0.40         6\n",
      "          89       1.00      0.33      0.50         6\n",
      "          90       0.10      0.17      0.12         6\n",
      "          91       0.20      0.17      0.18         6\n",
      "          92       0.00      0.00      0.00         6\n",
      "          93       0.00      0.00      0.00         7\n",
      "          94       0.00      0.00      0.00         7\n",
      "          95       0.38      1.00      0.55         6\n",
      "          96       0.00      0.00      0.00         7\n",
      "          97       0.36      0.83      0.50         6\n",
      "          98       0.31      0.67      0.42         6\n",
      "          99       1.00      1.00      1.00         6\n",
      "         100       1.00      1.00      1.00         6\n",
      "         101       0.40      0.33      0.36         6\n",
      "         102       0.44      0.67      0.53         6\n",
      "         103       0.46      1.00      0.63         6\n",
      "         104       0.46      1.00      0.63         6\n",
      "         105       1.00      1.00      1.00         6\n",
      "         106       1.00      1.00      1.00         6\n",
      "         107       0.40      1.00      0.57         6\n",
      "         108       0.17      0.17      0.17         6\n",
      "         109       0.00      0.00      0.00         7\n",
      "         110       0.00      0.00      0.00         7\n",
      "         111       0.00      0.00      0.00         7\n",
      "         112       1.00      1.00      1.00         6\n",
      "         113       0.67      1.00      0.80         6\n",
      "         114       0.00      0.00      0.00         7\n",
      "         115       0.00      0.00      0.00         6\n",
      "         116       1.00      0.17      0.29         6\n",
      "         117       0.43      1.00      0.60         6\n",
      "         118       0.27      0.50      0.35         6\n",
      "         119       0.20      0.50      0.29         6\n",
      "         120       0.00      0.00      0.00         6\n",
      "         121       0.00      0.00      0.00         7\n",
      "         122       0.83      0.83      0.83         6\n",
      "         123       0.33      0.50      0.40         6\n",
      "         124       0.00      0.00      0.00         7\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.60      1.00      0.75         6\n",
      "         127       0.00      0.00      0.00         6\n",
      "         128       0.00      0.00      0.00         7\n",
      "         129       0.00      0.00      0.00         7\n",
      "         130       0.24      0.67      0.35         6\n",
      "         131       0.40      0.33      0.36         6\n",
      "         132       0.17      0.17      0.17         6\n",
      "         133       0.86      1.00      0.92         6\n",
      "         134       0.50      0.33      0.40         6\n",
      "         135       0.67      0.33      0.44         6\n",
      "         136       0.25      0.17      0.20         6\n",
      "         137       0.33      0.17      0.22         6\n",
      "         138       0.00      0.00      0.00         7\n",
      "         139       0.13      0.67      0.22         6\n",
      "         140       1.00      1.00      1.00         6\n",
      "         141       1.00      1.00      1.00         6\n",
      "         142       0.00      0.00      0.00         6\n",
      "         143       0.00      0.00      0.00         7\n",
      "         144       0.16      0.50      0.24         6\n",
      "         145       0.00      0.00      0.00         6\n",
      "         146       1.00      1.00      1.00         6\n",
      "         147       0.00      0.00      0.00         6\n",
      "         148       0.00      0.00      0.00         6\n",
      "         149       0.00      0.00      0.00         6\n",
      "         150       0.50      0.17      0.25         6\n",
      "         151       0.00      0.00      0.00         7\n",
      "         152       0.00      0.00      0.00         7\n",
      "         153       0.00      0.00      0.00         7\n",
      "         154       0.46      1.00      0.63         6\n",
      "         155       0.57      0.67      0.62         6\n",
      "         156       0.00      0.00      0.00         7\n",
      "         157       0.20      0.67      0.31         6\n",
      "         158       0.00      0.00      0.00         6\n",
      "         159       0.50      0.67      0.57         6\n",
      "         160       0.33      0.17      0.22         6\n",
      "         161       0.00      0.00      0.00         6\n",
      "         162       0.67      0.67      0.67         6\n",
      "         163       0.40      0.33      0.36         6\n",
      "         164       0.35      1.00      0.52         6\n",
      "         165       0.25      0.33      0.29         6\n",
      "         166       0.00      0.00      0.00         6\n",
      "         167       0.00      0.00      0.00         6\n",
      "         168       0.33      0.17      0.22         6\n",
      "         169       1.00      1.00      1.00         6\n",
      "         170       0.75      0.50      0.60         6\n",
      "         171       0.00      0.00      0.00         7\n",
      "         172       0.24      0.83      0.37         6\n",
      "         173       0.00      0.00      0.00         7\n",
      "         174       0.46      1.00      0.63         6\n",
      "         175       1.00      1.00      1.00         6\n",
      "         176       0.60      0.50      0.55         6\n",
      "         177       1.00      0.67      0.80         6\n",
      "         178       0.86      1.00      0.92         6\n",
      "         179       0.00      0.00      0.00         7\n",
      "         180       1.00      1.00      1.00         6\n",
      "         181       0.17      0.17      0.17         6\n",
      "         182       0.00      0.00      0.00         7\n",
      "         183       1.00      0.33      0.50         6\n",
      "         184       0.50      0.33      0.40         6\n",
      "         185       0.00      0.00      0.00         6\n",
      "         186       0.50      0.50      0.50         6\n",
      "         187       0.33      0.17      0.22         6\n",
      "         188       0.00      0.00      0.00         7\n",
      "         189       1.00      1.00      1.00         6\n",
      "         190       0.33      0.17      0.22         6\n",
      "         191       0.00      0.00      0.00         7\n",
      "         192       0.27      0.50      0.35         6\n",
      "         193       1.00      1.00      1.00         6\n",
      "         194       0.17      0.17      0.17         6\n",
      "         195       0.30      0.50      0.37         6\n",
      "         196       0.00      0.00      0.00         7\n",
      "         197       0.30      0.50      0.37         6\n",
      "         198       0.43      1.00      0.60         6\n",
      "         199       1.00      1.00      1.00         6\n",
      "         200       0.40      0.33      0.36         6\n",
      "         201       0.00      0.00      0.00         7\n",
      "         202       0.75      1.00      0.86         6\n",
      "         203       0.46      1.00      0.63         6\n",
      "         204       0.22      0.67      0.33         6\n",
      "         205       1.00      1.00      1.00         6\n",
      "         206       0.46      1.00      0.63         6\n",
      "         207       0.40      0.33      0.36         6\n",
      "         208       0.20      0.50      0.29         6\n",
      "         209       0.00      0.00      0.00         7\n",
      "         210       0.00      0.00      0.00         7\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       0.60      0.50      0.55         6\n",
      "         213       0.00      0.00      0.00         7\n",
      "         214       0.00      0.00      0.00         6\n",
      "         215       0.33      0.33      0.33         6\n",
      "         216       1.00      1.00      1.00         6\n",
      "         217       1.00      0.17      0.29         6\n",
      "         218       0.27      0.50      0.35         6\n",
      "         219       0.57      0.67      0.62         6\n",
      "         220       0.25      1.00      0.40         6\n",
      "         221       0.00      0.00      0.00         6\n",
      "         222       0.00      0.00      0.00         7\n",
      "         223       0.46      1.00      0.63         6\n",
      "         224       0.00      0.00      0.00         7\n",
      "         225       0.00      0.00      0.00         7\n",
      "         226       0.00      0.00      0.00         7\n",
      "         227       0.86      1.00      0.92         6\n",
      "         228       0.40      1.00      0.57         6\n",
      "         229       0.17      0.17      0.17         6\n",
      "         230       1.00      1.00      1.00         6\n",
      "         231       0.50      0.50      0.50         6\n",
      "         232       0.00      0.00      0.00         7\n",
      "         233       0.50      0.50      0.50         6\n",
      "         234       0.33      0.17      0.22         6\n",
      "         235       0.00      0.00      0.00         7\n",
      "         236       0.00      0.00      0.00         7\n",
      "         237       0.00      0.00      0.00         7\n",
      "         238       0.00      0.00      0.00         7\n",
      "         239       0.16      1.00      0.27         6\n",
      "         240       1.00      1.00      1.00         6\n",
      "         241       1.00      1.00      1.00         6\n",
      "         242       1.00      1.00      1.00         6\n",
      "         243       1.00      1.00      1.00         6\n",
      "         244       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.45      1532\n",
      "   macro avg       0.39      0.47      0.40      1532\n",
      "weighted avg       0.38      0.45      0.38      1532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))\n",
    "\n",
    "# low precision scores indicate we need different data to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_all[\"PovertyRate\"]\n",
    "target_names = data_all[\"PovertyRate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all.drop(\"PovertyRate\", axis=1)\n",
    "data = data.drop(\"state_name\", axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n",
    "\n",
    "# shows the features most likely to make good predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest Classification Scores:\n",
    "## Trial 4 - Comparing Income and Part B Beneficiaries to Poverty Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations - Linear Regression model: Poverty Rate vs. Medicare Part B Beneficiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the data to X and y\n",
    "\n",
    "features = data_all[['beneficiaries_part_b']]\n",
    "y_data = data_all[['PovertyRate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using LinearRegression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7678160996440491\n",
      "Testing Score: 0.7613949120068373\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data and calculate the scores for the training and testing data\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "training_score = model.score(X_train, y_train)\n",
    "testing_score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Residuals for the Training and Testing data\n",
    "\n",
    "plt.scatter(model.predict(X_train), model.predict(X_train) - y_train, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test), model.predict(X_test) - y_test, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y.min(), xmax=y.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.savefig(\"D:\\\\BBC\\\\COPY_but-ind-data-pt-06-2020-u-c\\\\Linear_Regression_Model.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.16389193],\n",
       "       [15.61949118],\n",
       "       [10.49299037],\n",
       "       ...,\n",
       "       [14.77710076],\n",
       "       [16.19896267],\n",
       "       [16.36900317]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The predictions variable holds the predicted values of the features stored in x_test. Since we used the train_test_split \n",
    "# method to store the real values in y_test, we compare the values of the predictions array with the values of y_test by\n",
    "# using a scatterplot.\n",
    "\n",
    "plt.scatter(y_pred, y_test)\n",
    "plt.savefig(\"D:\\\\BBC\\\\COPY_but-ind-data-pt-06-2020-u-c\\\\Linear_Regression_Model_validation.png\")\n",
    "plt.show()\n",
    "\n",
    "# predicted values are very close to the actual values for the observations in the data set. A perfectly straight diagonal \n",
    "# line in this scatterplot would indicate that our model perfectly predicted the y-array values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot its residuals, which are the difference between the actual y-array values and the predicted y-array values.\n",
    "\n",
    "plt.hist(y_test - y_pred)\n",
    "plt.savefig(\"D:\\\\BBC\\\\COPY_but-ind-data-pt-06-2020-u-c\\\\Linear_Regression_Model_validation_hist.png\")\n",
    "plt.show()\n",
    "\n",
    "# residuals from our machine learning model appear to be close to normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the results\n",
    "\n",
    "# x_train=X_train.values.reshape(-1, 1)\n",
    "# Y_train=y_train.values.reshape(-1, 1)\n",
    "# x_test=X_test.reshape(-1, 1)\n",
    "\n",
    "# plt.scatter(x_train, Y_train, color='blue')\n",
    "# plt.plot(x_train, regressor.predict(x_test), color='red')\n",
    "# plt.title('Poverty Rate vs. Household Income and Medicare Part B Beneficiaries')\n",
    "# plt.xlabel('Household Income and Medicare Part B Beneficiaries')\n",
    "# plt.ylabel('Poverty Rate')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv]",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
